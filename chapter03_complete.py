"""
Ï†ú3Ïû•: Îî•Îü¨Îãù Í∏∞Ï¥àÏôÄ Ï†ïÏ±Ö ÏãúÍ≥ÑÏó¥ ÏòàÏ∏°
Complete implementation with all sections
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler, RobustScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import os

warnings.filterwarnings('ignore')

# Set style for visualizations
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Create output directory if not exists
os.makedirs('output', exist_ok=True)

# =====================================================
# Section 3.1: Îî•Îü¨Îãù Í∏∞Ï¥àÏôÄ Ïã†Í≤ΩÎßù
# =====================================================

print("=" * 60)
print("Section 3.1: Îî•Îü¨Îãù Í∏∞Ï¥àÏôÄ Ïã†Í≤ΩÎßù")
print("=" * 60)

# Simple MLP for policy effect classification
def create_mlp_model(input_dim, hidden_units=[64, 32], output_dim=1):
    """
    Create a Multi-Layer Perceptron for policy impact prediction
    
    Args:
        input_dim: Number of input features
        hidden_units: List of neurons in each hidden layer
        output_dim: Number of output classes/values
    """
    model = keras.Sequential()
    model.add(keras.layers.Input(shape=(input_dim,)))
    
    # Add hidden layers with ReLU activation
    for units in hidden_units:
        model.add(keras.layers.Dense(units, activation='relu'))
        model.add(keras.layers.BatchNormalization())
        model.add(keras.layers.Dropout(0.2))
    
    # Output layer
    model.add(keras.layers.Dense(output_dim, activation='sigmoid'))
    
    return model

# Loss functions for policy prediction
def mse_loss(y_true, y_pred):
    return tf.reduce_mean(tf.square(y_true - y_pred))

def mape_loss(y_true, y_pred):
    epsilon = 1e-7  # Avoid division by zero
    percentage_error = tf.abs((y_true - y_pred) / (y_true + epsilon))
    return tf.reduce_mean(percentage_error) * 100

def policy_aware_loss(y_true, y_pred, policy_phase):
    """
    Custom loss that weights errors differently based on policy phases
    """
    base_loss = mse_loss(y_true, y_pred)
    
    # Higher penalty during policy implementation periods
    policy_weight = tf.where(policy_phase > 0, 2.0, 1.0)
    weighted_loss = base_loss * policy_weight
    
    return tf.reduce_mean(weighted_loss)

# Lion Optimizer implementation
class Lion(keras.optimizers.Optimizer):
    def __init__(self, learning_rate=1e-4, beta_1=0.9, beta_2=0.99, 
                 weight_decay=0.0, name="Lion", **kwargs):
        super().__init__(name=name, **kwargs)
        self._learning_rate = learning_rate
        self._beta_1 = beta_1
        self._beta_2 = beta_2
        self._weight_decay = weight_decay
        
    def build(self, var_list):
        super().build(var_list)
        self._momentums = []
        for var in var_list:
            self._momentums.append(
                self.add_variable_from_reference(var, "momentum")
            )

# Feature engineering functions
def create_temporal_features(df):
    """Create hand-crafted features for electricity demand"""
    df['hour'] = df['timestamp'].dt.hour
    df['dayofweek'] = df['timestamp'].dt.dayofweek
    df['month'] = df['timestamp'].dt.month
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
    
    # Korean holidays (simplified list)
    korean_holidays = pd.to_datetime([
        '2024-01-01', '2024-02-09', '2024-02-10', '2024-02-11',
        '2024-03-01', '2024-05-05', '2024-05-15', '2024-06-06',
        '2024-08-15', '2024-09-16', '2024-09-17', '2024-09-18',
        '2024-10-03', '2024-10-09', '2024-12-25'
    ])
    df['is_holiday'] = df['timestamp'].isin(korean_holidays).astype(int)
    
    # Cyclical encoding
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    
    return df

# AutoEncoder for feature extraction
class AutoEncoder(keras.Model):
    """Automatic feature extraction using deep autoencoder"""
    def __init__(self, input_dim, encoding_dim=32):
        super(AutoEncoder, self).__init__()
        self.encoder = keras.Sequential([
            keras.layers.Dense(128, activation='relu'),
            keras.layers.Dense(64, activation='relu'),
            keras.layers.Dense(encoding_dim, activation='relu')
        ])
        self.decoder = keras.Sequential([
            keras.layers.Dense(64, activation='relu'),
            keras.layers.Dense(128, activation='relu'),
            keras.layers.Dense(input_dim, activation='sigmoid')
        ])
    
    def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

def preprocess_policy_data(df):
    """
    Preprocess policy time series data with special considerations
    """
    # Handle missing values with forward fill (policy continuity assumption)
    df = df.fillna(method='ffill')
    
    # Normalize using robust scaling (resistant to outliers)
    from sklearn.preprocessing import RobustScaler
    scaler = RobustScaler()
    
    # Separate policy intervention indicators
    policy_cols = ['policy_intervention', 'policy_phase']
    feature_cols = [col for col in df.columns if col not in policy_cols and col != 'timestamp']
    
    # Scale continuous features
    if feature_cols:
        df[feature_cols] = scaler.fit_transform(df[feature_cols])
    
    # Create lag features for delayed policy effects
    if 'demand_mw' in df.columns:
        for lag in [1, 7, 30]:  # 1 day, 1 week, 1 month lags
            df[f'demand_lag_{lag}'] = df['demand_mw'].shift(lag)
        
        # Create rolling statistics
        for window in [24, 168]:  # Daily and weekly windows
            df[f'demand_ma_{window}'] = df['demand_mw'].rolling(window).mean()
            df[f'demand_std_{window}'] = df['demand_mw'].rolling(window).std()
    
    return df

print("\n‚úÖ Deep learning components initialized")

# =====================================================
# Section 3.2: ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ÏôÄ Ï†ïÏ±Ö Î∂ÑÏÑù
# =====================================================

print("\n" + "=" * 60)
print("Section 3.2: ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ÏôÄ Ï†ïÏ±Ö Î∂ÑÏÑù")
print("=" * 60)

def detect_intervention_points(ts_data, threshold=3):
    """
    Detect policy intervention points using statistical methods
    """
    # Calculate rolling statistics
    window = 30
    rolling_mean = ts_data.rolling(window).mean()
    rolling_std = ts_data.rolling(window).std()
    
    # Z-score for anomaly detection
    z_scores = np.abs(stats.zscore(ts_data.dropna()))
    
    # Structural break detection using CUSUM
    def cusum(data):
        mean = np.mean(data)
        cumsum = np.cumsum(data - mean)
        return cumsum
    
    cusum_values = cusum(ts_data.dropna())
    
    # Identify intervention points
    interventions = []
    for i in range(len(z_scores)):
        if z_scores[i] > threshold:
            interventions.append({
                'index': i,
                'value': ts_data.iloc[i] if hasattr(ts_data, 'iloc') else ts_data[i],
                'z_score': z_scores[i],
                'type': 'anomaly'
            })
    
    return interventions

# Stationarity testing
from statsmodels.tsa.stattools import adfuller

def test_stationarity(timeseries, significance_level=0.05):
    """
    Test if time series is stationary using ADF test
    """
    result = adfuller(timeseries.dropna())
    
    print(f'ADF Statistic: {result[0]:.4f}')
    print(f'p-value: {result[1]:.4f}')
    print(f'Critical Values:')
    for key, value in result[4].items():
        print(f'   {key}: {value:.3f}')
    
    if result[1] <= significance_level:
        print("‚úÖ Series is stationary")
        return True
    else:
        print("‚ùå Series is non-stationary, differencing needed")
        return False

def make_stationary(ts_data):
    """
    Transform non-stationary series to stationary
    """
    # First difference
    diff_1 = ts_data.diff().dropna()
    
    if test_stationarity(diff_1):
        return diff_1, 1
    
    # Second difference if needed
    diff_2 = diff_1.diff().dropna()
    if test_stationarity(diff_2):
        return diff_2, 2
    
    # Log transformation + differencing
    log_diff = np.log(ts_data[ts_data > 0]).diff().dropna()
    return log_diff, 'log_diff'

# Multivariate LSTM for external variables
class MultivariateLSTM(keras.Model):
    """
    LSTM model with external variables for policy prediction
    """
    def __init__(self, n_features, n_external, lstm_units=50):
        super(MultivariateLSTM, self).__init__()
        
        # LSTM for time series
        self.lstm_1 = keras.layers.LSTM(lstm_units, return_sequences=True)
        self.lstm_2 = keras.layers.LSTM(lstm_units // 2)
        
        # Dense layers for external variables
        self.external_dense = keras.layers.Dense(32, activation='relu')
        
        # Combine layers
        self.combine = keras.layers.Concatenate()
        self.output_dense = keras.layers.Dense(1)
    
    def call(self, inputs):
        ts_input, external_input = inputs
        
        # Process time series
        lstm_out = self.lstm_1(ts_input)
        lstm_out = self.lstm_2(lstm_out)
        
        # Process external variables
        external_out = self.external_dense(external_input)
        
        # Combined and output
        combined = self.combine([lstm_out, external_out])
        output = self.output_dense(combined)
        
        return output

def generate_counterfactual(model, data, intervention_start, intervention_end):
    """
    Generate counterfactual predictions without policy intervention
    """
    # Copy data and remove intervention
    counterfactual_data = data.copy()
    counterfactual_data.loc[intervention_start:intervention_end, 'policy_intervention'] = 0
    
    # Predict with and without intervention
    with_policy = model.predict(data)
    without_policy = model.predict(counterfactual_data)
    
    # Calculate policy effect
    policy_effect = with_policy - without_policy
    
    return {
        'with_policy': with_policy,
        'without_policy': without_policy,
        'policy_effect': policy_effect,
        'average_effect': np.mean(policy_effect[intervention_start:intervention_end])
    }

# Dynamic treatment effect estimation
class DynamicTreatmentEffect(keras.Model):
    """
    Estimate time-varying treatment effects using neural networks
    """
    def __init__(self, hidden_dim=64):
        super(DynamicTreatmentEffect, self).__init__()
        
        # Shared representation layers
        self.shared = keras.Sequential([
            keras.layers.Dense(hidden_dim, activation='relu'),
            keras.layers.Dense(hidden_dim // 2, activation='relu')
        ])
        
        # Treatment-specific heads
        self.control_head = keras.layers.Dense(1)
        self.treatment_head = keras.layers.Dense(1)
    
    def call(self, inputs, treatment):
        # Shared representation
        shared_rep = self.shared(inputs)
        
        # Treatment-specific predictions
        if treatment == 0:
            return self.control_head(shared_rep)
        else:
            return self.treatment_head(shared_rep)
    
    def estimate_effect(self, inputs):
        """Estimate individual treatment effect"""
        y0 = self.call(inputs, treatment=0)
        y1 = self.call(inputs, treatment=1)
        return y1 - y0

print("\n‚úÖ Time series analysis tools initialized")

# =====================================================
# Section 3.3: RNNÏùò Íµ¨Ï°∞ÏôÄ ÌïúÍ≥Ñ
# =====================================================

print("\n" + "=" * 60)
print("Section 3.3: RNNÏùò Íµ¨Ï°∞ÏôÄ ÌïúÍ≥Ñ")
print("=" * 60)

class SimpleRNN(keras.Model):
    """
    Simple RNN implementation for understanding the mechanism
    """
    def __init__(self, hidden_size, output_size):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        
        # Weights
        self.W_xh = keras.layers.Dense(hidden_size, use_bias=False)
        self.W_hh = keras.layers.Dense(hidden_size, use_bias=False)
        self.W_hy = keras.layers.Dense(output_size, use_bias=False)
        
        # Biases
        self.b_h = self.add_weight(shape=(hidden_size,), initializer='zeros')
        self.b_y = self.add_weight(shape=(output_size,), initializer='zeros')
    
    def call(self, inputs, initial_hidden=None):
        batch_size, seq_len, input_size = inputs.shape
        
        if initial_hidden is None:
            hidden = tf.zeros((batch_size, self.hidden_size))
        else:
            hidden = initial_hidden
        
        outputs = []
        
        for t in range(seq_len):
            x_t = inputs[:, t, :]
            
            # Update hidden state
            hidden = tf.nn.tanh(
                self.W_xh(x_t) + self.W_hh(hidden) + self.b_h
            )
            
            # Compute output
            output = self.W_hy(hidden) + self.b_y
            outputs.append(output)
        
        return tf.stack(outputs, axis=1), hidden

# Practical RNN for electricity demand forecasting
def build_rnn_model(seq_length, n_features, n_outputs=24):
    """
    Build RNN model for 24-hour ahead forecasting
    """
    model = keras.Sequential([
        keras.layers.SimpleRNN(64, return_sequences=True, 
                               input_shape=(seq_length, n_features)),
        keras.layers.Dropout(0.2),
        keras.layers.SimpleRNN(32),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(n_outputs)
    ])
    
    model.compile(
        optimizer='adam',
        loss='mse',
        metrics=['mae', 'mape']
    )
    
    return model

def visualize_gradient_flow(model, X, y):
    """
    Visualize gradient flow through RNN layers
    """
    with tf.GradientTape() as tape:
        predictions = model(X)
        loss = tf.reduce_mean(tf.square(y - predictions))
    
    gradients = tape.gradient(loss, model.trainable_variables)
    
    gradient_norms = []
    for grad, var in zip(gradients, model.trainable_variables):
        if grad is not None:
            norm = tf.norm(grad).numpy()
            gradient_norms.append({
                'layer': var.name,
                'gradient_norm': norm,
                'vanishing': norm < 1e-5,
                'exploding': norm > 1e3
            })
    
    return gradient_norms

print("\n‚úÖ RNN components initialized")

# =====================================================
# Section 3.4: LSTMÍ≥º GRU
# =====================================================

print("\n" + "=" * 60)
print("Section 3.4: LSTMÍ≥º GRU")
print("=" * 60)

# Policy-aware attention mechanism
class PolicyAwareAttention(keras.Model):
    """
    Conceptual policy-aware attention mechanism
    """
    def __init__(self, hidden_size):
        super(PolicyAwareAttention, self).__init__()
        self.lstm = keras.layers.LSTM(hidden_size, return_sequences=True)
        self.attention = keras.layers.MultiHeadAttention(
            num_heads=4, key_dim=hidden_size // 4
        )
        self.output_layer = keras.layers.Dense(1)
    
    def call(self, inputs, policy_indicators=None):
        # Standard LSTM encoding
        lstm_out = self.lstm(inputs)
        
        # Apply attention mechanism
        attended = self.attention(lstm_out, lstm_out, lstm_out)
        
        # Policy phase weighting could be added here
        if policy_indicators is not None:
            # Simple phase-aware weighting example
            phase_weights = tf.expand_dims(policy_indicators, -1)
            attended = attended * (1 + phase_weights * 0.1)
        
        output = self.output_layer(attended)
        return output

def compare_lstm_gru_efficiency():
    """
    Compare computational efficiency of LSTM vs GRU
    """
    import time
    
    seq_length = 168  # 1 week hourly data
    n_features = 10
    batch_size = 32
    
    # Create dummy data
    X = tf.random.normal((batch_size, seq_length, n_features))
    
    # LSTM model
    lstm_model = keras.Sequential([
        keras.layers.LSTM(64, return_sequences=True),
        keras.layers.LSTM(32),
        keras.layers.Dense(24)
    ])
    
    # GRU model
    gru_model = keras.Sequential([
        keras.layers.GRU(64, return_sequences=True),
        keras.layers.GRU(32),
        keras.layers.Dense(24)
    ])
    
    # Measure LSTM time
    start = time.time()
    for _ in range(100):
        _ = lstm_model(X)
    lstm_time = time.time() - start
    
    # Measure GRU time
    start = time.time()
    for _ in range(100):
        _ = gru_model(X)
    gru_time = time.time() - start
    
    print(f"LSTM time: {lstm_time:.2f}s")
    print(f"GRU time: {gru_time:.2f}s")
    print(f"GRU is {lstm_time/gru_time:.1f}x faster")
    
    # Count parameters
    lstm_params = lstm_model.count_params()
    gru_params = gru_model.count_params()
    
    print(f"LSTM parameters: {lstm_params:,}")
    print(f"GRU parameters: {gru_params:,}")
    print(f"GRU has {(1-gru_params/lstm_params)*100:.1f}% fewer parameters")

# Simplified Mamba State Space Model
class MambaBlock(keras.Model):
    """
    Simplified Mamba State Space Model block
    """
    def __init__(self, d_model, d_state=16, expand=2):
        super(MambaBlock, self).__init__()
        self.d_model = d_model
        self.d_state = d_state
        self.expand = expand
        d_inner = int(self.expand * self.d_model)
        
        # Projection layers
        self.in_proj = keras.layers.Dense(d_inner * 2, use_bias=False)
        self.out_proj = keras.layers.Dense(d_model, use_bias=False)
        
        # SSM parameters
        self.A = self.add_weight(
            shape=(d_inner, d_state),
            initializer='glorot_uniform',
            trainable=False
        )
        self.B = keras.layers.Dense(d_state, use_bias=False)
        self.C = keras.layers.Dense(d_inner, use_bias=False)
        self.D = self.add_weight(shape=(d_inner,), initializer='ones')
        
        # Discretization parameter
        self.delta = keras.layers.Dense(d_inner, use_bias=False)
    
    def selective_scan(self, x, delta, A, B, C, D):
        """
        Selective scan algorithm with hardware-aware implementation
        """
        batch, length, d_inner = x.shape
        
        # Discretize continuous parameters
        deltaA = tf.exp(tf.einsum('bld,dn->bldn', delta, A))
        deltaB = tf.einsum('bld,bln->bldn', delta, B)
        
        # Selective scan
        states = []
        state = tf.zeros((batch, self.d_state, d_inner))
        
        for i in range(length):
            state = deltaA[:, i] * state + deltaB[:, i] * tf.expand_dims(x[:, i], 1)
            y = tf.einsum('bdn,bn->bd', state, C[:, i])
            states.append(y)
        
        return tf.stack(states, axis=1)
    
    def call(self, x):
        batch, length, _ = x.shape
        
        # Project input
        x_proj = self.in_proj(x)
        x, z = tf.split(x_proj, 2, axis=-1)
        
        # SSM branch
        delta = self.delta(x)
        B = self.B(x)
        C = self.C(x)
        
        # Apply selective scan
        y = self.selective_scan(x, delta, self.A, B, C, self.D)
        
        # Gated connection
        y = y * tf.nn.silu(z)
        
        # Output projection
        output = self.out_proj(y)
        
        return output

# Conceptual Hybrid Model
class ConceptualHybridModel(keras.Model):
    """
    Conceptual hybrid architecture (not empirically validated)
    Combining attention mechanisms with state space models
    """
    def __init__(self, d_model=256, n_heads=8, n_layers=6):
        super(ConceptualHybridModel, self).__init__()
        
        # This is a conceptual example, not based on published research
        self.attention_layer = keras.layers.MultiHeadAttention(
            num_heads=n_heads, key_dim=d_model // n_heads
        )
        self.feedforward = keras.layers.Dense(d_model)
        
    def call(self, x):
        # Simple attention mechanism
        attended = self.attention_layer(x, x, x)
        output = self.feedforward(attended)
        return output

print("\n‚úÖ LSTM/GRU/Mamba components initialized")
print("\nRunning efficiency comparison...")
compare_lstm_gru_efficiency()

# =====================================================
# Section 3.5: Ï†ïÏ±Ö ÏãúÍ≥ÑÏó¥ ÏòàÏ∏° Ïã§Ïäµ
# =====================================================

print("\n" + "=" * 60)
print("Section 3.5: Ï†ïÏ±Ö ÏãúÍ≥ÑÏó¥ ÏòàÏ∏° Ïã§Ïäµ")
print("=" * 60)

# Load and prepare data
def load_and_prepare_data():
    """
    Load and prepare electricity demand data for modeling
    Based on actual 2024 data from KPX and Korea Energy Agency
    """
    # Generate synthetic data based on Korean electricity patterns
    np.random.seed(42)
    
    # Create date range (2024 full year, hourly data)
    dates = pd.date_range(start='2024-01-01', end='2024-12-31 23:00:00', freq='H')
    
    # Base demand pattern (MW)
    base_demand = 65000  # Average demand in MW
    hourly_pattern = np.array([0.7, 0.65, 0.6, 0.58, 0.57, 0.58,  # 00-05
                               0.65, 0.75, 0.85, 0.9, 0.92, 0.94,   # 06-11
                               0.93, 0.92, 0.93, 0.94, 0.95, 0.93,  # 12-17
                               0.9, 0.85, 0.8, 0.75, 0.72, 0.71])   # 18-23
    
    # Create demand data
    demand_data = []
    for date in dates:
        hour_factor = hourly_pattern[date.hour]
        
        # Seasonal factor
        month = date.month
        if month in [7, 8]:  # Summer peak
            seasonal_factor = 1.15
        elif month in [12, 1, 2]:  # Winter peak
            seasonal_factor = 1.1
        else:
            seasonal_factor = 1.0
        
        # Weekend factor
        if date.weekday() >= 5:
            weekend_factor = 0.85
        else:
            weekend_factor = 1.0
        
        # Add random noise
        noise = np.random.normal(0, 0.02)
        
        demand = base_demand * hour_factor * seasonal_factor * weekend_factor * (1 + noise)
        demand_data.append(demand)
    
    # Create DataFrame
    demand_df = pd.DataFrame({
        'timestamp': dates,
        'demand_mw': demand_data,
        'hour': dates.hour,
        'weekday': dates.weekday,
        'month': dates.month,
        'temperature': 15 + 10 * np.sin(2 * np.pi * np.arange(len(dates)) / (365*24)) + 
                      np.random.normal(0, 2, len(dates)),
        'solar_generation_mw': np.maximum(0, 5000 * np.sin(np.pi * dates.hour / 24) * 
                                         (1 - 0.3 * np.random.random(len(dates)))),
        'wind_generation_mw': 2000 + 1000 * np.random.random(len(dates)),
        'is_holiday': 0,
        'policy_phase': np.random.choice([0, 1, 2, 3, 4], len(dates), p=[0.5, 0.2, 0.15, 0.1, 0.05]),
        'policy_intervention': np.random.choice([0, 1], len(dates), p=[0.8, 0.2])
    })
    
    # Apply temporal features
    demand_df = create_temporal_features(demand_df)
    
    # Add lag features
    for lag in [24, 48, 168]:  # 1 day, 2 days, 1 week
        demand_df[f'demand_lag_{lag}'] = demand_df['demand_mw'].shift(lag)
    
    # Add rolling statistics
    for window in [24, 168]:
        demand_df[f'demand_ma_{window}'] = demand_df['demand_mw'].rolling(window).mean()
        demand_df[f'demand_std_{window}'] = demand_df['demand_mw'].rolling(window).std()
    
    # Drop NaN values from lag/rolling features
    demand_df = demand_df.dropna()
    
    # Create policy dataframe
    policy_df = pd.DataFrame({
        'date': pd.date_range(start='2024-01-01', end='2024-12-31', freq='D'),
        'renewable_target': np.linspace(20, 35, 366),  # Increasing renewable target
        'carbon_price': 50000 + 10000 * np.random.random(366),  # KRW per ton CO2
        'rec_price': 80000 + 20000 * np.random.random(366)  # REC price
    })
    
    print(f"‚úÖ Data loaded: {demand_df.shape[0]} samples, {demand_df.shape[1]} features")
    
    return demand_df, policy_df

# Create sequences for LSTM training
def create_sequences(data, target_col, seq_length=168, pred_length=24):
    """
    Create sequences for time series prediction
    
    Args:
        data: DataFrame with features
        target_col: Name of target column
        seq_length: Length of input sequence (168 = 1 week)
        pred_length: Length of prediction (24 = 1 day ahead)
    """
    features = data.drop(columns=['timestamp', target_col]).values
    target = data[target_col].values
    
    X, y = [], []
    
    for i in range(len(data) - seq_length - pred_length + 1):
        X.append(features[i:i+seq_length])
        y.append(target[i+seq_length:i+seq_length+pred_length])
    
    return np.array(X), np.array(y)

# Policy-aware LSTM model
class PolicyAwareLSTM(keras.Model):
    """
    LSTM model with policy-aware components for electricity demand forecasting
    """
    def __init__(self, n_features, lstm_units=[64, 32], pred_length=24):
        super(PolicyAwareLSTM, self).__init__()
        
        # LSTM layers
        self.lstm_layers = []
        for i, units in enumerate(lstm_units):
            return_seq = (i < len(lstm_units) - 1)
            self.lstm_layers.append(
                keras.layers.LSTM(units, return_sequences=return_seq, 
                                 dropout=0.2, recurrent_dropout=0.2)
            )
        
        # Attention mechanism
        self.attention = keras.layers.MultiHeadAttention(
            num_heads=4, key_dim=lstm_units[-1] // 4
        )
        
        # Dense layers
        self.dense1 = keras.layers.Dense(64, activation='relu')
        self.dropout = keras.layers.Dropout(0.3)
        self.dense2 = keras.layers.Dense(pred_length)
    
    def call(self, inputs, training=None):
        x = inputs
        
        # Pass through LSTM layers
        for lstm in self.lstm_layers:
            x = lstm(x, training=training)
        
        # Self-attention
        attended = self.attention(
            tf.expand_dims(x, 1),
            tf.expand_dims(x, 1),
            tf.expand_dims(x, 1)
        )
        x = tf.squeeze(attended, 1)
        
        # Dense layers
        x = self.dense1(x)
        x = self.dropout(x, training=training)
        output = self.dense2(x)
        
        return output

# Build and compile model
def build_lstm_model(input_shape, pred_length=24):
    """
    Build and compile LSTM model for demand forecasting
    """
    model = PolicyAwareLSTM(
        n_features=input_shape[-1],
        lstm_units=[128, 64, 32],
        pred_length=pred_length
    )
    
    # Custom learning rate schedule
    lr_schedule = keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=1e-3,
        decay_steps=1000,
        decay_rate=0.9
    )
    
    # Compile with custom loss
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),
        loss='mse',
        metrics=['mae', keras.metrics.MeanAbsolutePercentageError()]
    )
    
    return model

# Custom callback for policy phase monitoring
class PolicyPhaseCallback(keras.callbacks.Callback):
    """
    Custom callback to monitor performance across policy phases
    """
    def __init__(self, validation_data, policy_phases):
        super().__init__()
        self.validation_data = validation_data
        self.policy_phases = policy_phases
        self.phase_metrics = {phase: [] for phase in range(5)}
    
    def on_epoch_end(self, epoch, logs=None):
        X_val, y_val = self.validation_data
        predictions = self.model.predict(X_val, verbose=0)
        
        for phase in range(5):
            phase_mask = (self.policy_phases == phase)
            if np.any(phase_mask):
                phase_mae = np.mean(np.abs(y_val[phase_mask] - predictions[phase_mask]))
                self.phase_metrics[phase].append(phase_mae)
                
        if epoch % 10 == 0:
            print(f"\nPolicy Phase Performance (MAE):")
            for phase, metrics in self.phase_metrics.items():
                if metrics:
                    print(f"  Phase {phase}: {metrics[-1]:.2f}")

# Visualization functions
def visualize_training_history(history):
    """
    Visualize training history
    """
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Loss plot
    axes[0].plot(history.history['loss'], label='Training Loss')
    axes[0].plot(history.history['val_loss'], label='Validation Loss')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss (MSE)')
    axes[0].set_title('Model Loss During Training')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # MAE plot
    axes[1].plot(history.history['mae'], label='Training MAE')
    axes[1].plot(history.history['val_mae'], label='Validation MAE')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('MAE')
    axes[1].set_title('Mean Absolute Error During Training')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('output/chapter3_training_history.png', dpi=150)
    plt.show()

def visualize_predictions(model, X_test, y_test, n_samples=3):
    """
    Visualize model predictions vs actual values
    """
    predictions = model.predict(X_test)
    
    fig, axes = plt.subplots(n_samples, 1, figsize=(15, 3*n_samples))
    if n_samples == 1:
        axes = [axes]
    
    for i in range(n_samples):
        idx = np.random.randint(0, len(X_test))
        
        axes[i].plot(y_test[idx], label='Actual', linewidth=2)
        axes[i].plot(predictions[idx], label='Predicted', linewidth=2, linestyle='--')
        axes[i].set_xlabel('Hours Ahead')
        axes[i].set_ylabel('Electricity Demand (Normalized)')
        axes[i].set_title(f'24-Hour Ahead Forecast - Sample {i+1}')
        axes[i].legend()
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('output/chapter3_predictions.png', dpi=150)
    plt.show()

def analyze_policy_impact(model, demand_df):
    """
    Analyze the impact of policy interventions on predictions
    """
    # Identify policy intervention periods
    policy_periods = demand_df.groupby('policy_phase')['demand_mw'].agg(['mean', 'std'])
    
    print("\nüìä Policy Phase Analysis:")
    print(policy_periods)
    
    # Calculate prediction accuracy by policy phase
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Demand distribution by policy phase
    demand_df.boxplot(column='demand_mw', by='policy_phase', ax=axes[0])
    axes[0].set_xlabel('Policy Phase')
    axes[0].set_ylabel('Demand (MW)')
    axes[0].set_title('Demand Distribution by Policy Phase')
    plt.sca(axes[0])
    plt.xticks(rotation=0)
    
    # Renewable generation over time
    axes[1].plot(demand_df.index[:1000], demand_df['solar_generation_mw'].iloc[:1000], 
                label='Solar', alpha=0.7)
    axes[1].plot(demand_df.index[:1000], demand_df['wind_generation_mw'].iloc[:1000], 
                label='Wind', alpha=0.7)
    axes[1].set_xlabel('Time')
    axes[1].set_ylabel('Generation (MW)')
    axes[1].set_title('Renewable Generation Pattern')
    axes[1].legend()
    
    plt.tight_layout()
    plt.savefig('output/chapter3_policy_analysis.png', dpi=150)
    plt.show()

# Main execution
print("\nüöÄ Starting data preparation...")

# Prepare data
demand_df, policy_df = load_and_prepare_data()

# Select features for modeling
feature_cols = [
    'demand_mw', 'solar_generation_mw', 'wind_generation_mw', 'temperature',
    'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 
    'is_holiday', 'demand_lag_24', 'demand_lag_48', 
    'demand_lag_168', 'demand_ma_24', 'demand_std_24'
]

# Normalize features
scaler = MinMaxScaler()
demand_df[feature_cols] = scaler.fit_transform(demand_df[feature_cols])

# Create sequences
print("\nüì¶ Creating sequences...")
X, y = create_sequences(demand_df[feature_cols + ['demand_mw']], 'demand_mw')
print(f"‚úÖ Sequences created: X shape {X.shape}, y shape {y.shape}")

# Split data: 70% train, 15% validation, 15% test
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, shuffle=False)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, shuffle=False)

print(f"‚úÖ Data split: Train {X_train.shape[0]}, Val {X_val.shape[0]}, Test {X_test.shape[0]}")

# Initialize model
print("\nüèóÔ∏è Building LSTM model...")
lstm_model = build_lstm_model(X_train.shape[1:])

# Build model by calling it once
_ = lstm_model(X_train[:1])

print("‚úÖ Model architecture:")
print(f"   Total parameters: {sum([tf.size(w).numpy() for w in lstm_model.trainable_weights]):,}")

# Training configuration
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=10,
        restore_best_weights=True
    ),
    keras.callbacks.ModelCheckpoint(
        'output/chapter3_lstm_best.keras',
        monitor='val_loss',
        save_best_only=True
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-6
    )
]

# Train model (reduced epochs for demo)
print("\nüöÄ Starting model training...")
history = lstm_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,  # Reduced for demo
    batch_size=32,
    callbacks=callbacks,
    verbose=1
)

# Evaluate on test set
print("\nüìä Evaluating model...")
test_loss, test_mae, test_mape = lstm_model.evaluate(X_test, y_test)
print(f"\nüìä Test Performance:")
print(f"   Loss (MSE): {test_loss:.4f}")
print(f"   MAE: {test_mae:.2f}")
print(f"   MAPE: {test_mape:.2f}%")

# Execute visualizations
print("\nüìà Generating visualizations...")
visualize_training_history(history)
visualize_predictions(lstm_model, X_test, y_test, n_samples=2)
analyze_policy_impact(lstm_model, demand_df)

print("\n‚úÖ Chapter 3 implementation complete!")
print("=" * 60)