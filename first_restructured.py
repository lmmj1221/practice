"""
ì œ3ì¥: ë”¥ëŸ¬ë‹ ê¸°ì´ˆì™€ ì •ì±… ì‹œê³„ì—´ ì˜ˆì¸¡
êµìœ¡ìš© ì‹œê°í™”ì™€ ì‹¤ì œ ë¶„ì„ì„ ë¶„ë¦¬í•œ êµ¬ì¡°í™”ëœ ë²„ì „
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler, RobustScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import os
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs('output', exist_ok=True)
os.makedirs('data', exist_ok=True)
os.makedirs('visualizations', exist_ok=True)

# =====================================================
# ì‚¬ìš©ì ëª¨ë“œ ì„ íƒ
# =====================================================

def select_mode():
    """ì‹¤í–‰ ëª¨ë“œ ì„ íƒ"""
    print("\n" + "="*60)
    print("ë”¥ëŸ¬ë‹ ì •ì±… ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("="*60)
    print("\nì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. êµìœ¡ ëª¨ë“œ (ê°œë… ì„¤ëª… ë° ì‹œê°í™”)")
    print("2. ì‹¤ì „ ë¶„ì„ ëª¨ë“œ (ë°ì´í„° ë¶„ì„)")
    print("3. ì „ì²´ ì‹¤í–‰ (êµìœ¡ + ë¶„ì„)")

    while True:
        try:
            choice = input("\nì„ íƒ (1/2/3): ").strip()
            if choice in ['1', '2', '3']:
                return int(choice)
            else:
                print("ì˜¬ë°”ë¥¸ ì„ íƒì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1, 2, ë˜ëŠ” 3)")
        except:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

# =====================================================
# Part 1: êµìœ¡ìš© ì‹œê°í™” í•¨ìˆ˜ë“¤
# =====================================================

def demonstrate_neural_networks():
    """ì‹ ê²½ë§ ê°œë…ì„ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n" + "="*50)
    print("ì‹ ê²½ë§ êµ¬ì¡° ì‹œê°í™”")
    print("="*50)

    # ê°„ë‹¨í•œ ì‹ ê²½ë§ êµ¬ì¡° ì‹œê°í™”
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # 1. í¼ì…‰íŠ¸ë¡  ì‹œê°í™”
    ax = axes[0]
    ax.set_title('ë‹¨ì¼ í¼ì…‰íŠ¸ë¡ ', fontsize=12)

    # ì…ë ¥ ë…¸ë“œ
    for i in range(3):
        circle = plt.Circle((0.2, 0.3 + i*0.2), 0.05, color='lightblue', ec='black')
        ax.add_patch(circle)
        ax.text(0.05, 0.3 + i*0.2, f'x{i+1}', fontsize=10)
        ax.arrow(0.25, 0.3 + i*0.2, 0.3, 0.1 - i*0.05, head_width=0.02, head_length=0.02, fc='gray')

    # ì¶œë ¥ ë…¸ë“œ
    circle = plt.Circle((0.7, 0.5), 0.05, color='lightgreen', ec='black')
    ax.add_patch(circle)
    ax.text(0.85, 0.5, 'y', fontsize=10)

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # 2. ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ì‹œê°í™”
    ax = axes[1]
    ax.set_title('ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (MLP)', fontsize=12)

    layers = [3, 4, 2, 1]
    layer_positions = [0.2, 0.4, 0.6, 0.8]

    for l_idx, (layer_size, x_pos) in enumerate(zip(layers, layer_positions)):
        for n_idx in range(layer_size):
            y_pos = 0.5 + (n_idx - layer_size/2) * 0.15

            if l_idx == 0:
                color = 'lightblue'
            elif l_idx == len(layers) - 1:
                color = 'lightgreen'
            else:
                color = 'lightyellow'

            circle = plt.Circle((x_pos, y_pos), 0.03, color=color, ec='black')
            ax.add_patch(circle)

            # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            if l_idx < len(layers) - 1:
                next_layer_size = layers[l_idx + 1]
                next_x_pos = layer_positions[l_idx + 1]
                for next_idx in range(next_layer_size):
                    next_y_pos = 0.5 + (next_idx - next_layer_size/2) * 0.15
                    ax.plot([x_pos, next_x_pos], [y_pos, next_y_pos],
                           'gray', alpha=0.3, linewidth=0.5)

    ax.text(0.2, 0.05, 'ì…ë ¥ì¸µ', fontsize=10, ha='center')
    ax.text(0.5, 0.05, 'ì€ë‹‰ì¸µ', fontsize=10, ha='center')
    ax.text(0.8, 0.05, 'ì¶œë ¥ì¸µ', fontsize=10, ha='center')

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # 3. í™œì„±í™” í•¨ìˆ˜ ì‹œê°í™”
    ax = axes[2]
    ax.set_title('ì£¼ìš” í™œì„±í™” í•¨ìˆ˜', fontsize=12)

    x = np.linspace(-3, 3, 100)

    # ReLU
    relu = np.maximum(0, x)
    ax.plot(x, relu, label='ReLU', linewidth=2)

    # Sigmoid
    sigmoid = 1 / (1 + np.exp(-x))
    ax.plot(x, sigmoid, label='Sigmoid', linewidth=2)

    # Tanh
    tanh = np.tanh(x)
    ax.plot(x, tanh, label='Tanh', linewidth=2)

    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.set_xlabel('ì…ë ¥ê°’')
    ax.set_ylabel('ì¶œë ¥ê°’')

    plt.tight_layout()
    plt.savefig('visualizations/neural_networks_demo.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("âœ… ì‹ ê²½ë§ êµ¬ì¡° ì‹œê°í™” ì™„ë£Œ (visualizations/neural_networks_demo.png)")

def demonstrate_time_series_concepts():
    """ì‹œê³„ì—´ ë¶„ì„ ê°œë…ì„ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n" + "="*50)
    print("ì‹œê³„ì—´ ë¶„ì„ ê°œë… ì‹œê°í™”")
    print("="*50)

    # ìƒ˜í”Œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=365, freq='D')

    # íŠ¸ë Œë“œ + ê³„ì ˆì„± + ë…¸ì´ì¦ˆ
    trend = np.linspace(100, 150, 365)
    seasonal = 10 * np.sin(2 * np.pi * np.arange(365) / 365)
    noise = np.random.normal(0, 5, 365)
    ts = trend + seasonal + noise

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 1. ì›ë³¸ ì‹œê³„ì—´
    ax = axes[0, 0]
    ax.plot(dates, ts, color='blue', alpha=0.7)
    ax.set_title('ì‹œê³„ì—´ ë°ì´í„° ì˜ˆì‹œ', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('ê°’')
    ax.grid(True, alpha=0.3)

    # 2. ì‹œê³„ì—´ ë¶„í•´
    ax = axes[0, 1]
    ax.plot(dates, trend, label='íŠ¸ë Œë“œ', linewidth=2, color='red')
    ax.plot(dates, seasonal + 125, label='ê³„ì ˆì„±', linewidth=2, color='green')
    ax.plot(dates, noise + 100, label='ë…¸ì´ì¦ˆ', linewidth=1, color='gray', alpha=0.5)
    ax.set_title('ì‹œê³„ì—´ êµ¬ì„± ìš”ì†Œ', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('ê°’')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 3. ìê¸°ìƒê´€ í•¨ìˆ˜ (ACF)
    ax = axes[1, 0]
    from statsmodels.graphics.tsaplots import plot_acf
    plot_acf(ts, lags=50, ax=ax)
    ax.set_title('ìê¸°ìƒê´€ í•¨ìˆ˜ (ACF)', fontsize=12)

    # 4. ì •ì±… ê°œì… íš¨ê³¼ ì‹œê°í™”
    ax = axes[1, 1]

    # ì •ì±… ê°œì… ì‹œë®¬ë ˆì´ì…˜
    policy_start = 200
    ts_with_policy = ts.copy()
    ts_with_policy[policy_start:] += 20  # ì •ì±… íš¨ê³¼

    ax.plot(dates, ts, label='ì •ì±… ê°œì… ì „', color='blue', alpha=0.7)
    ax.plot(dates, ts_with_policy, label='ì •ì±… ê°œì… í›„', color='red', alpha=0.7)
    ax.axvline(x=dates[policy_start], color='green', linestyle='--', label='ì •ì±… ì‹œí–‰ì¼')
    ax.set_title('ì •ì±… ê°œì… íš¨ê³¼', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('ê°’')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('visualizations/time_series_demo.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("âœ… ì‹œê³„ì—´ ê°œë… ì‹œê°í™” ì™„ë£Œ (visualizations/time_series_demo.png)")

def demonstrate_rnn_concepts():
    """RNN ê°œë…ì„ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n" + "="*50)
    print("RNN êµ¬ì¡° ì‹œê°í™”")
    print("="*50)

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # 1. ê¸°ë³¸ RNN êµ¬ì¡°
    ax = axes[0]
    ax.set_title('ê¸°ë³¸ RNN êµ¬ì¡°', fontsize=12)

    # RNN ì…€ ê·¸ë¦¬ê¸°
    for t in range(3):
        x_pos = 0.3 + t * 0.2

        # ì…ë ¥
        ax.arrow(x_pos, 0.2, 0, 0.15, head_width=0.02, head_length=0.02, fc='blue')
        ax.text(x_pos, 0.15, f'x{t}', fontsize=10, ha='center')

        # RNN ì…€
        rect = plt.Rectangle((x_pos-0.05, 0.4), 0.1, 0.2,
                            facecolor='lightgreen', edgecolor='black')
        ax.add_patch(rect)
        ax.text(x_pos, 0.5, 'RNN', fontsize=10, ha='center')

        # ì¶œë ¥
        ax.arrow(x_pos, 0.6, 0, 0.15, head_width=0.02, head_length=0.02, fc='red')
        ax.text(x_pos, 0.8, f'h{t}', fontsize=10, ha='center')

        # ì€ë‹‰ ìƒíƒœ ì—°ê²°
        if t < 2:
            ax.arrow(x_pos+0.05, 0.5, 0.1, 0, head_width=0.02, head_length=0.02, fc='gray')

    ax.set_xlim(0.1, 0.9)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # 2. Vanishing Gradient ë¬¸ì œ
    ax = axes[1]
    ax.set_title('Gradient Vanishing ë¬¸ì œ', fontsize=12)

    timesteps = np.arange(1, 11)
    gradient_flow = 0.5 ** timesteps  # ì§€ìˆ˜ì  ê°ì†Œ

    ax.bar(timesteps, gradient_flow, color='red', alpha=0.7)
    ax.set_xlabel('ì‹œê°„ ë‹¨ê³„')
    ax.set_ylabel('Gradient í¬ê¸°')
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)

    # 3. ì‹œí€€ìŠ¤ ê¸¸ì´ë³„ ì„±ëŠ¥
    ax = axes[2]
    ax.set_title('ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥', fontsize=12)

    seq_lengths = np.array([10, 20, 30, 50, 100, 200])
    rnn_performance = 0.9 * np.exp(-seq_lengths/50)
    lstm_performance = 0.9 - 0.1 * seq_lengths/200

    ax.plot(seq_lengths, rnn_performance, 'o-', label='ê¸°ë³¸ RNN', linewidth=2)
    ax.plot(seq_lengths, lstm_performance, 's-', label='LSTM', linewidth=2)
    ax.set_xlabel('ì‹œí€€ìŠ¤ ê¸¸ì´')
    ax.set_ylabel('ì •í™•ë„')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('visualizations/rnn_concepts_demo.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("âœ… RNN ê°œë… ì‹œê°í™” ì™„ë£Œ (visualizations/rnn_concepts_demo.png)")

def demonstrate_lstm_gru():
    """LSTMê³¼ GRU êµ¬ì¡°ë¥¼ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n" + "="*50)
    print("LSTM/GRU êµ¬ì¡° ì‹œê°í™”")
    print("="*50)

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 1. LSTM ê²Œì´íŠ¸ ë™ì‘
    ax = axes[0, 0]
    ax.set_title('LSTM ê²Œì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜', fontsize=12)

    gates = ['Forget Gate', 'Input Gate', 'Output Gate']
    values = [0.7, 0.9, 0.6]
    colors = ['red', 'blue', 'green']

    bars = ax.bar(gates, values, color=colors, alpha=0.7)
    ax.set_ylabel('ê²Œì´íŠ¸ ê°’')
    ax.set_ylim(0, 1)
    ax.grid(True, alpha=0.3, axis='y')

    for bar, val in zip(bars, values):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}', ha='center', va='bottom')

    # 2. GRU vs LSTM íŒŒë¼ë¯¸í„° ìˆ˜
    ax = axes[0, 1]
    ax.set_title('ëª¨ë¸ ë³µì¡ë„ ë¹„êµ', fontsize=12)

    models = ['RNN', 'GRU', 'LSTM']
    params = [100, 300, 400]  # ìƒëŒ€ì  íŒŒë¼ë¯¸í„° ìˆ˜

    bars = ax.bar(models, params, color=['gray', 'orange', 'purple'], alpha=0.7)
    ax.set_ylabel('íŒŒë¼ë¯¸í„° ìˆ˜ (ìƒëŒ€ê°’)')
    ax.grid(True, alpha=0.3, axis='y')

    # 3. ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ ëŠ¥ë ¥
    ax = axes[1, 0]
    ax.set_title('ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ ëŠ¥ë ¥', fontsize=12)

    distance = np.arange(1, 101)
    rnn_ability = np.exp(-distance/10)
    lstm_ability = np.exp(-distance/50)
    gru_ability = np.exp(-distance/40)

    ax.plot(distance, rnn_ability, label='RNN', linewidth=2)
    ax.plot(distance, lstm_ability, label='LSTM', linewidth=2)
    ax.plot(distance, gru_ability, label='GRU', linewidth=2)
    ax.set_xlabel('ì‹œê°„ ê°„ê²©')
    ax.set_ylabel('ì •ë³´ ë³´ì¡´ ëŠ¥ë ¥')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 4. í•™ìŠµ ì†ë„ ë¹„êµ
    ax = axes[1, 1]
    ax.set_title('í•™ìŠµ ìˆ˜ë ´ ì†ë„', fontsize=12)

    epochs = np.arange(1, 51)
    rnn_loss = 0.5 * np.exp(-epochs/10) + 0.15
    lstm_loss = 0.5 * np.exp(-epochs/15) + 0.05
    gru_loss = 0.5 * np.exp(-epochs/12) + 0.08

    ax.plot(epochs, rnn_loss, label='RNN', linewidth=2)
    ax.plot(epochs, lstm_loss, label='LSTM', linewidth=2)
    ax.plot(epochs, gru_loss, label='GRU', linewidth=2)
    ax.set_xlabel('ì—í­')
    ax.set_ylabel('ì†ì‹¤ê°’')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('visualizations/lstm_gru_demo.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("âœ… LSTM/GRU êµ¬ì¡° ì‹œê°í™” ì™„ë£Œ (visualizations/lstm_gru_demo.png)")

# =====================================================
# Part 2: ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜ë“¤
# =====================================================

def generate_and_save_data(output_dir='data'):
    """í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥"""
    print("\n" + "="*50)
    print("ë°ì´í„° ìƒì„± ë° ì €ì¥")
    print("="*50)

    np.random.seed(42)

    # 1. ì „ë ¥ ìˆ˜ìš” ë°ì´í„° ìƒì„±
    dates = pd.date_range('2022-01-01', '2023-12-31', freq='H')
    n_hours = len(dates)

    # ê¸°ë³¸ íŒ¨í„´
    hourly_pattern = np.array([0.7, 0.65, 0.6, 0.58, 0.57, 0.58,  # 0-5ì‹œ
                               0.65, 0.75, 0.85, 0.9, 0.92, 0.94,   # 6-11ì‹œ
                               0.93, 0.92, 0.91, 0.9, 0.88, 0.87,   # 12-17ì‹œ
                               0.9, 0.95, 0.97, 0.85, 0.8, 0.75])   # 18-23ì‹œ

    # ê³„ì ˆ íŒ¨í„´
    day_of_year = dates.dayofyear
    seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * day_of_year / 365 - np.pi/2)

    # ì „ë ¥ ìˆ˜ìš” ìƒì„±
    base_demand = 50000  # MW
    demand = []
    for i, date in enumerate(dates):
        hour = date.hour
        daily_factor = hourly_pattern[hour]
        season_factor = seasonal_factor[i % len(seasonal_factor)]
        noise = np.random.normal(0, 0.05)
        demand_value = base_demand * daily_factor * season_factor * (1 + noise)
        demand.append(demand_value)

    demand_df = pd.DataFrame({
        'timestamp': dates,
        'demand_mw': demand,
        'temperature': 15 + 10 * np.sin(2 * np.pi * day_of_year[:n_hours] / 365) + np.random.normal(0, 3, n_hours),
        'humidity': 60 + 20 * np.sin(2 * np.pi * day_of_year[:n_hours] / 365 + np.pi/4) + np.random.normal(0, 5, n_hours),
        'is_weekend': dates.weekday.isin([5, 6]).astype(int)
    })

    # 2. ì¬ìƒì—ë„ˆì§€ ì •ì±… ë°ì´í„° ìƒì„±
    policy_changes = pd.date_range('2022-01-01', '2023-12-31', freq='M')
    policy_levels = np.cumsum(np.random.uniform(0, 2, len(policy_changes)))

    policy_df = pd.DataFrame({
        'timestamp': policy_changes,
        'renewable_target': 20 + policy_levels,
        'subsidy_rate': 0.1 + 0.01 * policy_levels,
        'carbon_tax': 10 + 2 * policy_levels
    })

    # 3. ì „ë ¥ ì‹œì¥ ë°ì´í„° ìƒì„±
    market_df = pd.DataFrame({
        'timestamp': dates,
        'smp': 80 + 20 * np.sin(2 * np.pi * day_of_year[:n_hours] / 365) + np.random.normal(0, 10, n_hours),
        'rec_price': 50 + 10 * np.sin(2 * np.pi * day_of_year[:n_hours] / 365 + np.pi/3) + np.random.normal(0, 5, n_hours),
        'lng_price': 10 + 2 * np.sin(2 * np.pi * day_of_year[:n_hours] / 365 - np.pi/4) + np.random.normal(0, 1, n_hours)
    })

    # ë°ì´í„° ì €ì¥
    demand_df.to_csv(f'{output_dir}/energy_demand.csv', index=False)
    policy_df.to_csv(f'{output_dir}/renewable_policy.csv', index=False)
    market_df.to_csv(f'{output_dir}/electricity_market.csv', index=False)

    print(f"âœ… ì „ë ¥ ìˆ˜ìš” ë°ì´í„° ì €ì¥: {output_dir}/energy_demand.csv")
    print(f"âœ… ì¬ìƒì—ë„ˆì§€ ì •ì±… ë°ì´í„° ì €ì¥: {output_dir}/renewable_policy.csv")
    print(f"âœ… ì „ë ¥ ì‹œì¥ ë°ì´í„° ì €ì¥: {output_dir}/electricity_market.csv")

    return demand_df, policy_df, market_df

def load_and_prepare_data(data_dir='data', generate_if_missing=True):
    """ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ëª¨ë¸ë§ì„ ìœ„í•´ ì¤€ë¹„"""

    # íŒŒì¼ í™•ì¸
    required_files = ['energy_demand.csv', 'renewable_policy.csv', 'electricity_market.csv']
    files_exist = all(os.path.exists(f'{data_dir}/{f}') for f in required_files)

    if not files_exist:
        if generate_if_missing:
            print("âš ï¸ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
            generate_and_save_data(data_dir)
        else:
            raise FileNotFoundError("í•„ìš”í•œ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
    demand_df = pd.read_csv(f'{data_dir}/energy_demand.csv', parse_dates=['timestamp'])
    policy_df = pd.read_csv(f'{data_dir}/renewable_policy.csv', parse_dates=['timestamp'])
    market_df = pd.read_csv(f'{data_dir}/electricity_market.csv', parse_dates=['timestamp'])

    # ë°ì´í„° ë³‘í•©
    merged_df = demand_df.merge(market_df, on='timestamp', how='left')
    merged_df = pd.merge_asof(merged_df.sort_values('timestamp'),
                              policy_df.sort_values('timestamp'),
                              on='timestamp',
                              direction='backward')
    merged_df = merged_df.fillna(method='ffill')

    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(merged_df)} ë ˆì½”ë“œ")

    return merged_df

def create_sequences(data, sequence_length=24, target_col='demand_mw'):
    """ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œí€€ìŠ¤ ìƒì„±"""

    # timestamp ì—´ì´ ìˆìœ¼ë©´ ì œì™¸
    cols_to_drop = [col for col in ['timestamp', target_col] if col in data.columns]
    features = data.drop(columns=cols_to_drop).values
    targets = data[target_col].values

    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(features[i:i+sequence_length])
        y.append(targets[i+sequence_length])

    return np.array(X), np.array(y)

def build_lstm_model(input_shape):
    """LSTM ëª¨ë¸ êµ¬ì¶•"""
    model = keras.Sequential([
        keras.layers.LSTM(128, return_sequences=True, input_shape=input_shape),
        keras.layers.Dropout(0.2),
        keras.layers.LSTM(64, return_sequences=True),
        keras.layers.Dropout(0.2),
        keras.layers.LSTM(32),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

def build_gru_model(input_shape):
    """GRU ëª¨ë¸ êµ¬ì¶•"""
    model = keras.Sequential([
        keras.layers.GRU(128, return_sequences=True, input_shape=input_shape),
        keras.layers.Dropout(0.2),
        keras.layers.GRU(64, return_sequences=True),
        keras.layers.Dropout(0.2),
        keras.layers.GRU(32),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

def train_and_evaluate_models(data):
    """ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
    print("\n" + "="*50)
    print("ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")
    print("="*50)

    # ë°ì´í„° ì „ì²˜ë¦¬
    scaler = MinMaxScaler()
    numeric_columns = data.select_dtypes(include=[np.number]).columns
    data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

    # ì‹œí€€ìŠ¤ ìƒì„±
    X, y = create_sequences(data, sequence_length=24)

    # í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• 
    n_samples = len(X)
    train_size = int(0.7 * n_samples)
    val_size = int(0.15 * n_samples)

    X_train = X[:train_size]
    y_train = y[:train_size]
    X_val = X[train_size:train_size+val_size]
    y_val = y[train_size:train_size+val_size]
    X_test = X[train_size+val_size:]
    y_test = y[train_size+val_size:]

    print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}")
    print(f"ê²€ì¦ ë°ì´í„°: {X_val.shape}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")

    # LSTM ëª¨ë¸ í•™ìŠµ
    print("\nğŸ”„ LSTM ëª¨ë¸ í•™ìŠµ ì¤‘...")
    lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))

    lstm_history = lstm_model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=10,
        batch_size=32,
        verbose=1
    )

    # GRU ëª¨ë¸ í•™ìŠµ
    print("\nğŸ”„ GRU ëª¨ë¸ í•™ìŠµ ì¤‘...")
    gru_model = build_gru_model((X_train.shape[1], X_train.shape[2]))

    gru_history = gru_model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=10,
        batch_size=32,
        verbose=1
    )

    # ëª¨ë¸ í‰ê°€
    print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    lstm_test_loss, lstm_test_mae = lstm_model.evaluate(X_test, y_test, verbose=0)
    gru_test_loss, gru_test_mae = gru_model.evaluate(X_test, y_test, verbose=0)

    print(f"LSTM - Test Loss: {lstm_test_loss:.4f}, Test MAE: {lstm_test_mae:.4f}")
    print(f"GRU  - Test Loss: {gru_test_loss:.4f}, Test MAE: {gru_test_mae:.4f}")

    # ì˜ˆì¸¡ ì‹œê°í™”
    visualize_predictions(lstm_model, gru_model, X_test, y_test, scaler)

    return lstm_model, gru_model, lstm_history, gru_history

def visualize_predictions(lstm_model, gru_model, X_test, y_test, scaler):
    """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""

    # ì˜ˆì¸¡
    lstm_pred = lstm_model.predict(X_test)
    gru_pred = gru_model.predict(X_test)

    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 1, figsize=(15, 10))

    # ìƒ˜í”Œ êµ¬ê°„ ì„ íƒ (ì²˜ìŒ 200ê°œ)
    n_show = min(200, len(y_test))

    # LSTM ì˜ˆì¸¡
    ax = axes[0]
    ax.plot(y_test[:n_show], label='ì‹¤ì œê°’', alpha=0.7)
    ax.plot(lstm_pred[:n_show], label='LSTM ì˜ˆì¸¡', alpha=0.7)
    ax.set_title('LSTM ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼')
    ax.set_xlabel('ì‹œê°„')
    ax.set_ylabel('ì „ë ¥ ìˆ˜ìš” (ì •ê·œí™”)')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # GRU ì˜ˆì¸¡
    ax = axes[1]
    ax.plot(y_test[:n_show], label='ì‹¤ì œê°’', alpha=0.7)
    ax.plot(gru_pred[:n_show], label='GRU ì˜ˆì¸¡', alpha=0.7)
    ax.set_title('GRU ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼')
    ax.set_xlabel('ì‹œê°„')
    ax.set_ylabel('ì „ë ¥ ìˆ˜ìš” (ì •ê·œí™”)')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('output/model_predictions.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("âœ… ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì™„ë£Œ (output/model_predictions.png)")

def analyze_policy_impact(data, model):
    """ì •ì±… ì˜í–¥ ë¶„ì„"""
    print("\n" + "="*50)
    print("ì •ì±… ì˜í–¥ ë¶„ì„")
    print("="*50)

    # ì •ì±… ë³€í™” ì‹œì  ì°¾ê¸°
    policy_cols = ['renewable_target', 'subsidy_rate', 'carbon_tax']

    fig, axes = plt.subplots(len(policy_cols), 1, figsize=(15, 10))

    for idx, col in enumerate(policy_cols):
        if col in data.columns:
            ax = axes[idx]

            # ì •ì±… ë³€ìˆ˜ì™€ ì „ë ¥ ìˆ˜ìš”ì˜ ê´€ê³„
            ax2 = ax.twinx()

            ax.plot(data.index[:1000], data[col].iloc[:1000],
                   color='blue', alpha=0.7, label=col)
            ax2.plot(data.index[:1000], data['demand_mw'].iloc[:1000],
                    color='red', alpha=0.5, label='ì „ë ¥ ìˆ˜ìš”')

            ax.set_xlabel('ì‹œê°„')
            ax.set_ylabel(col, color='blue')
            ax2.set_ylabel('ì „ë ¥ ìˆ˜ìš”', color='red')
            ax.tick_params(axis='y', labelcolor='blue')
            ax2.tick_params(axis='y', labelcolor='red')

            ax.set_title(f'{col}ì™€ ì „ë ¥ ìˆ˜ìš”ì˜ ê´€ê³„')
            ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('output/policy_impact_analysis.png', dpi=150, bbox_inches='tight')
    plt.show()

    print("âœ… ì •ì±… ì˜í–¥ ë¶„ì„ ì™„ë£Œ (output/policy_impact_analysis.png)")

# =====================================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# =====================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # ëª¨ë“œ ì„ íƒ
    mode = select_mode()

    # êµìœ¡ ëª¨ë“œ ì‹¤í–‰
    if mode in [1, 3]:
        print("\n" + "="*60)
        print("êµìœ¡ ëª¨ë“œ ì‹¤í–‰")
        print("="*60)

        demonstrate_neural_networks()
        demonstrate_time_series_concepts()
        demonstrate_rnn_concepts()
        demonstrate_lstm_gru()

        print("\nâœ… êµìœ¡ ëª¨ë“œ ì™„ë£Œ!")

    # ì‹¤ì „ ë¶„ì„ ëª¨ë“œ ì‹¤í–‰
    if mode in [2, 3]:
        print("\n" + "="*60)
        print("ì‹¤ì „ ë¶„ì„ ëª¨ë“œ ì‹¤í–‰")
        print("="*60)

        # ë°ì´í„° ì¤€ë¹„
        data = load_and_prepare_data()

        # ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
        lstm_model, gru_model, lstm_hist, gru_hist = train_and_evaluate_models(data)

        # ì •ì±… ì˜í–¥ ë¶„ì„
        analyze_policy_impact(data, lstm_model)

        print("\nâœ… ì‹¤ì „ ë¶„ì„ ëª¨ë“œ ì™„ë£Œ!")

    print("\n" + "="*60)
    print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    print("="*60)

if __name__ == "__main__":
    main()