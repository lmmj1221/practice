"""
ì œ3ì¥: ë”¥ëŸ¬ë‹ ê¸°ì´ˆì™€ ì •ì±… ì‹œê³„ì—´ ì˜ˆì¸¡
ì™„ì „ ìë™ ì‹¤í–‰ ë²„ì „ - ì‚¬ìš©ì ì…ë ¥ ì—†ì´ ëª¨ë“  ë¶„ì„ ìˆ˜í–‰
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import os
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs('output', exist_ok=True)
os.makedirs('data', exist_ok=True)
os.makedirs('visualizations', exist_ok=True)

print("\n" + "="*60)
print("ë”¥ëŸ¬ë‹ ì •ì±… ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ - ìë™ ì‹¤í–‰")
print("="*60)

# =====================================================
# Part 1: êµìœ¡ìš© ì‹œê°í™” í•¨ìˆ˜ë“¤
# =====================================================

def demonstrate_neural_networks():
    """ì‹ ê²½ë§ ê°œë…ì„ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n[1/5] ì‹ ê²½ë§ êµ¬ì¡° ì‹œê°í™” ìƒì„± ì¤‘...")

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # 1. í¼ì…‰íŠ¸ë¡  ì‹œê°í™”
    ax = axes[0]
    ax.set_title('ë‹¨ì¼ í¼ì…‰íŠ¸ë¡ ', fontsize=12)

    # ì…ë ¥ ë…¸ë“œ
    for i in range(3):
        circle = plt.Circle((0.2, 0.3 + i*0.2), 0.05, color='lightblue', ec='black')
        ax.add_patch(circle)
        ax.text(0.05, 0.3 + i*0.2, f'x{i+1}', fontsize=10)

    # ì¶œë ¥ ë…¸ë“œ
    circle = plt.Circle((0.7, 0.5), 0.05, color='lightgreen', ec='black')
    ax.add_patch(circle)
    ax.text(0.85, 0.5, 'y', fontsize=10)

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # 2. ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ì‹œê°í™”
    ax = axes[1]
    ax.set_title('ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (MLP)', fontsize=12)

    layers = [3, 4, 2, 1]
    layer_positions = [0.2, 0.4, 0.6, 0.8]

    for l_idx, (layer_size, x_pos) in enumerate(zip(layers, layer_positions)):
        for n_idx in range(layer_size):
            y_pos = 0.5 + (n_idx - layer_size/2) * 0.15

            if l_idx == 0:
                color = 'lightblue'
            elif l_idx == len(layers) - 1:
                color = 'lightgreen'
            else:
                color = 'lightyellow'

            circle = plt.Circle((x_pos, y_pos), 0.03, color=color, ec='black')
            ax.add_patch(circle)

    ax.text(0.2, 0.05, 'ì…ë ¥ì¸µ', fontsize=10, ha='center')
    ax.text(0.5, 0.05, 'ì€ë‹‰ì¸µ', fontsize=10, ha='center')
    ax.text(0.8, 0.05, 'ì¶œë ¥ì¸µ', fontsize=10, ha='center')

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # 3. í™œì„±í™” í•¨ìˆ˜ ì‹œê°í™”
    ax = axes[2]
    ax.set_title('ì£¼ìš” í™œì„±í™” í•¨ìˆ˜', fontsize=12)

    x = np.linspace(-3, 3, 100)
    relu = np.maximum(0, x)
    sigmoid = 1 / (1 + np.exp(-x))
    tanh = np.tanh(x)

    ax.plot(x, relu, label='ReLU', linewidth=2)
    ax.plot(x, sigmoid, label='Sigmoid', linewidth=2)
    ax.plot(x, tanh, label='Tanh', linewidth=2)

    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.set_xlabel('ì…ë ¥ê°’')
    ax.set_ylabel('ì¶œë ¥ê°’')

    plt.tight_layout()
    plt.savefig('visualizations/neural_networks_demo.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("   âœ… ì‹ ê²½ë§ êµ¬ì¡° ì‹œê°í™” ì €ì¥ ì™„ë£Œ")

def demonstrate_time_series_concepts():
    """ì‹œê³„ì—´ ë¶„ì„ ê°œë…ì„ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n[2/5] ì‹œê³„ì—´ ë¶„ì„ ê°œë… ì‹œê°í™” ìƒì„± ì¤‘...")

    # ìƒ˜í”Œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=365, freq='D')

    # íŠ¸ë Œë“œ + ê³„ì ˆì„± + ë…¸ì´ì¦ˆ
    trend = np.linspace(100, 150, 365)
    seasonal = 10 * np.sin(2 * np.pi * np.arange(365) / 365)
    noise = np.random.normal(0, 5, 365)
    ts = trend + seasonal + noise

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 1. ì›ë³¸ ì‹œê³„ì—´
    ax = axes[0, 0]
    ax.plot(dates, ts, color='blue', alpha=0.7)
    ax.set_title('ì‹œê³„ì—´ ë°ì´í„° ì˜ˆì‹œ', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('ê°’')
    ax.grid(True, alpha=0.3)

    # 2. ì‹œê³„ì—´ ë¶„í•´
    ax = axes[0, 1]
    ax.plot(dates, trend, label='íŠ¸ë Œë“œ', linewidth=2, color='red')
    ax.plot(dates, seasonal + 125, label='ê³„ì ˆì„±', linewidth=2, color='green')
    ax.plot(dates, noise + 100, label='ë…¸ì´ì¦ˆ', linewidth=1, color='gray', alpha=0.5)
    ax.set_title('ì‹œê³„ì—´ êµ¬ì„± ìš”ì†Œ', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('ê°’')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 3. ìê¸°ìƒê´€ í•¨ìˆ˜ (ê°„ë‹¨í•œ ë²„ì „)
    ax = axes[1, 0]
    lags = range(50)
    acf_values = [np.corrcoef(ts[:-lag-1], ts[lag+1:])[0,1] if lag > 0 else 1.0 for lag in lags]
    ax.bar(lags, acf_values, color='blue', alpha=0.7)
    ax.set_title('ìê¸°ìƒê´€ í•¨ìˆ˜ (ACF)', fontsize=12)
    ax.set_xlabel('ì‹œì°¨')
    ax.set_ylabel('ìƒê´€ê³„ìˆ˜')
    ax.grid(True, alpha=0.3)

    # 4. ì •ì±… ê°œì… íš¨ê³¼ ì‹œê°í™”
    ax = axes[1, 1]
    policy_start = 200
    ts_with_policy = ts.copy()
    ts_with_policy[policy_start:] += 20  # ì •ì±… íš¨ê³¼

    ax.plot(dates, ts, label='ì •ì±… ê°œì… ì „', color='blue', alpha=0.7)
    ax.plot(dates, ts_with_policy, label='ì •ì±… ê°œì… í›„', color='red', alpha=0.7)
    ax.axvline(x=dates[policy_start], color='green', linestyle='--', label='ì •ì±… ì‹œí–‰ì¼')
    ax.set_title('ì •ì±… ê°œì… íš¨ê³¼', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('ê°’')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('visualizations/time_series_demo.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("   âœ… ì‹œê³„ì—´ ê°œë… ì‹œê°í™” ì €ì¥ ì™„ë£Œ")

def demonstrate_lstm_gru():
    """LSTMê³¼ GRU ì„±ëŠ¥ ë¹„êµë¥¼ ì‹œê°í™”í•˜ì—¬ ì„¤ëª…"""
    print("\n[3/5] LSTM/GRU ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ìƒì„± ì¤‘...")

    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # 1. ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ ëŠ¥ë ¥
    ax = axes[0]
    ax.set_title('ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµ ëŠ¥ë ¥', fontsize=12)

    distance = np.arange(1, 101)
    rnn_ability = np.exp(-distance/10)
    lstm_ability = np.exp(-distance/50)
    gru_ability = np.exp(-distance/40)

    ax.plot(distance, rnn_ability, label='RNN', linewidth=2)
    ax.plot(distance, lstm_ability, label='LSTM', linewidth=2)
    ax.plot(distance, gru_ability, label='GRU', linewidth=2)
    ax.set_xlabel('ì‹œê°„ ê°„ê²©')
    ax.set_ylabel('ì •ë³´ ë³´ì¡´ ëŠ¥ë ¥')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 2. í•™ìŠµ ì†ë„ ë¹„êµ
    ax = axes[1]
    ax.set_title('í•™ìŠµ ìˆ˜ë ´ ì†ë„', fontsize=12)

    epochs = np.arange(1, 51)
    rnn_loss = 0.5 * np.exp(-epochs/10) + 0.15
    lstm_loss = 0.5 * np.exp(-epochs/15) + 0.05
    gru_loss = 0.5 * np.exp(-epochs/12) + 0.08

    ax.plot(epochs, rnn_loss, label='RNN', linewidth=2)
    ax.plot(epochs, lstm_loss, label='LSTM', linewidth=2)
    ax.plot(epochs, gru_loss, label='GRU', linewidth=2)
    ax.set_xlabel('ì—í­')
    ax.set_ylabel('ì†ì‹¤ê°’')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('visualizations/lstm_gru_comparison.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("   âœ… LSTM/GRU ë¹„êµ ì‹œê°í™” ì €ì¥ ì™„ë£Œ")

# =====================================================
# Part 2: ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜ë“¤
# =====================================================

def generate_and_save_data(output_dir='data'):
    """í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥"""
    print("\n[4/5] ë°ì´í„° ìƒì„± ë° ì €ì¥ ì¤‘...")

    np.random.seed(42)

    # 1. ì „ë ¥ ìˆ˜ìš” ë°ì´í„° ìƒì„± (1ê°œì›” ë¶„ëŸ‰ë§Œ - ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´)
    dates = pd.date_range('2024-01-01', '2024-01-31', freq='H')
    n_hours = len(dates)

    # ê¸°ë³¸ íŒ¨í„´
    hourly_pattern = np.array([0.7, 0.65, 0.6, 0.58, 0.57, 0.58,  # 0-5ì‹œ
                               0.65, 0.75, 0.85, 0.9, 0.92, 0.94,   # 6-11ì‹œ
                               0.93, 0.92, 0.91, 0.9, 0.88, 0.87,   # 12-17ì‹œ
                               0.9, 0.95, 0.97, 0.85, 0.8, 0.75])   # 18-23ì‹œ

    # ì „ë ¥ ìˆ˜ìš” ìƒì„±
    base_demand = 50000  # MW
    demand = []
    for i, date in enumerate(dates):
        hour = date.hour
        daily_factor = hourly_pattern[hour]
        noise = np.random.normal(0, 0.05)
        demand_value = base_demand * daily_factor * (1 + noise)
        demand.append(demand_value)

    demand_df = pd.DataFrame({
        'timestamp': dates,
        'demand_mw': demand,
        'temperature': 5 + np.random.normal(0, 3, n_hours),  # ê²¨ìš¸ ì˜¨ë„
        'humidity': 60 + np.random.normal(0, 5, n_hours),
        'is_weekend': dates.weekday.isin([5, 6]).astype(int)
    })

    # 2. ì¬ìƒì—ë„ˆì§€ ì •ì±… ë°ì´í„° ìƒì„±
    policy_changes = pd.date_range('2024-01-01', '2024-01-31', freq='D')
    policy_levels = np.cumsum(np.random.uniform(0, 0.5, len(policy_changes)))

    policy_df = pd.DataFrame({
        'timestamp': policy_changes,
        'renewable_target': 20 + policy_levels,
        'subsidy_rate': 0.1 + 0.001 * policy_levels,
        'carbon_tax': 10 + 0.5 * policy_levels
    })

    # 3. ì „ë ¥ ì‹œì¥ ë°ì´í„° ìƒì„±
    market_df = pd.DataFrame({
        'timestamp': dates,
        'smp': 100 + np.random.normal(0, 10, n_hours),
        'rec_price': 50 + np.random.normal(0, 5, n_hours),
        'lng_price': 12 + np.random.normal(0, 1, n_hours)
    })

    # ë°ì´í„° ì €ì¥
    demand_df.to_csv(f'{output_dir}/energy_demand.csv', index=False)
    policy_df.to_csv(f'{output_dir}/renewable_policy.csv', index=False)
    market_df.to_csv(f'{output_dir}/electricity_market.csv', index=False)

    print(f"   âœ… ì „ë ¥ ìˆ˜ìš” ë°ì´í„° ì €ì¥: {output_dir}/energy_demand.csv")
    print(f"   âœ… ì¬ìƒì—ë„ˆì§€ ì •ì±… ë°ì´í„° ì €ì¥: {output_dir}/renewable_policy.csv")
    print(f"   âœ… ì „ë ¥ ì‹œì¥ ë°ì´í„° ì €ì¥: {output_dir}/electricity_market.csv")

    return demand_df, policy_df, market_df

def quick_analysis_and_visualization(demand_df, policy_df, market_df):
    """ë¹ ë¥¸ ë¶„ì„ ë° ì‹œê°í™”"""
    print("\n[5/5] ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ìƒì„± ì¤‘...")

    # ë°ì´í„° ë³‘í•©
    merged_df = demand_df.merge(market_df, on='timestamp', how='left')

    # ê°„ë‹¨í•œ í†µê³„
    print("\nğŸ“Š ë°ì´í„° ìš”ì•½ í†µê³„:")
    print(f"   - í‰ê·  ì „ë ¥ ìˆ˜ìš”: {demand_df['demand_mw'].mean():.0f} MW")
    print(f"   - ìµœëŒ€ ì „ë ¥ ìˆ˜ìš”: {demand_df['demand_mw'].max():.0f} MW")
    print(f"   - ìµœì†Œ ì „ë ¥ ìˆ˜ìš”: {demand_df['demand_mw'].min():.0f} MW")
    print(f"   - í‰ê·  SMP: {market_df['smp'].mean():.1f} ì›/kWh")

    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 1. ì¼ë³„ ì „ë ¥ ìˆ˜ìš” íŒ¨í„´
    ax = axes[0, 0]
    daily_demand = demand_df.groupby(demand_df['timestamp'].dt.date)['demand_mw'].mean()
    ax.plot(daily_demand.index, daily_demand.values, linewidth=2, color='blue')
    ax.set_title('ì¼ë³„ í‰ê·  ì „ë ¥ ìˆ˜ìš”', fontsize=12)
    ax.set_xlabel('ë‚ ì§œ')
    ax.set_ylabel('í‰ê·  ìˆ˜ìš” (MW)')
    ax.grid(True, alpha=0.3)
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)

    # 2. ì‹œê°„ëŒ€ë³„ í‰ê·  ìˆ˜ìš”
    ax = axes[0, 1]
    hourly_demand = demand_df.groupby(demand_df['timestamp'].dt.hour)['demand_mw'].mean()
    ax.plot(hourly_demand.index, hourly_demand.values, linewidth=2, color='red', marker='o')
    ax.set_title('ì‹œê°„ëŒ€ë³„ í‰ê·  ì „ë ¥ ìˆ˜ìš”', fontsize=12)
    ax.set_xlabel('ì‹œê°„')
    ax.set_ylabel('í‰ê·  ìˆ˜ìš” (MW)')
    ax.grid(True, alpha=0.3)

    # 3. ìˆ˜ìš”ì™€ ì˜¨ë„ì˜ ê´€ê³„
    ax = axes[1, 0]
    ax.scatter(demand_df['temperature'], demand_df['demand_mw'], alpha=0.5, s=10)
    ax.set_title('ì˜¨ë„ì™€ ì „ë ¥ ìˆ˜ìš”ì˜ ê´€ê³„', fontsize=12)
    ax.set_xlabel('ì˜¨ë„ (Â°C)')
    ax.set_ylabel('ìˆ˜ìš” (MW)')
    ax.grid(True, alpha=0.3)

    # 4. SMP ê°€ê²© ì¶”ì´
    ax = axes[1, 1]
    ax.plot(market_df['timestamp'][:24*7], market_df['smp'][:24*7], linewidth=1.5, color='green')
    ax.set_title('ì²« ì£¼ SMP ê°€ê²© ì¶”ì´', fontsize=12)
    ax.set_xlabel('ì‹œê°„')
    ax.set_ylabel('SMP (ì›/kWh)')
    ax.grid(True, alpha=0.3)
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)

    plt.tight_layout()
    plt.savefig('output/analysis_results.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("   âœ… ë¶„ì„ ê²°ê³¼ ì‹œê°í™” ì €ì¥ ì™„ë£Œ")

def build_and_train_simple_model(demand_df):
    """ê°„ë‹¨í•œ LSTM ëª¨ë¸ í•™ìŠµ (ë°ëª¨ìš©)"""
    print("\nğŸ¤– ê°„ë‹¨í•œ LSTM ëª¨ë¸ í•™ìŠµ ì¤‘...")

    # ë°ì´í„° ì¤€ë¹„
    data = demand_df[['demand_mw', 'temperature', 'humidity', 'is_weekend']].values

    # ì •ê·œí™”
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data)

    # ì‹œí€€ìŠ¤ ìƒì„± (24ì‹œê°„ ë‹¨ìœ„)
    sequence_length = 24
    X, y = [], []

    for i in range(len(data_scaled) - sequence_length):
        X.append(data_scaled[i:i+sequence_length])
        y.append(data_scaled[i+sequence_length, 0])  # demand_mwë§Œ ì˜ˆì¸¡

    X = np.array(X)
    y = np.array(y)

    if len(X) == 0:
        print("   âš ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ ìƒëµ")
        return

    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    # ê°„ë‹¨í•œ LSTM ëª¨ë¸
    model = keras.Sequential([
        keras.layers.LSTM(32, input_shape=(sequence_length, 4)),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    # í•™ìŠµ (ì—í­ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ ë¹ ë¥´ê²Œ ì‹¤í–‰)
    print("   ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    history = model.fit(
        X_train, y_train,
        validation_split=0.2,
        epochs=3,  # ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ 3 ì—í­ë§Œ
        batch_size=32,
        verbose=0  # ì¶œë ¥ ìµœì†Œí™”
    )

    # í‰ê°€
    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)
    print(f"   âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - Test MAE: {test_mae:.4f}")

    # ì˜ˆì¸¡ ì‹œê°í™”
    predictions = model.predict(X_test, verbose=0)

    plt.figure(figsize=(12, 5))
    plt.plot(y_test[:100], label='ì‹¤ì œê°’', alpha=0.7)
    plt.plot(predictions[:100], label='ì˜ˆì¸¡ê°’', alpha=0.7)
    plt.title('LSTM ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 100ê°œ ìƒ˜í”Œ)')
    plt.xlabel('ì‹œê°„')
    plt.ylabel('ì „ë ¥ ìˆ˜ìš” (ì •ê·œí™”)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('output/lstm_predictions.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("   âœ… ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì €ì¥ ì™„ë£Œ")

# =====================================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# =====================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì™„ì „ ìë™ ì‹¤í–‰"""

    start_time = datetime.now()

    print("\nğŸš€ í”„ë¡œê·¸ë¨ ìë™ ì‹¤í–‰ ì‹œì‘...")
    print(f"   ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")

    # Part 1: êµìœ¡ìš© ì‹œê°í™”
    print("\n" + "="*60)
    print("Part 1: êµìœ¡ìš© ê°œë… ì‹œê°í™”")
    print("="*60)

    demonstrate_neural_networks()
    demonstrate_time_series_concepts()
    demonstrate_lstm_gru()

    # Part 2: ë°ì´í„° ìƒì„± ë° ë¶„ì„
    print("\n" + "="*60)
    print("Part 2: ë°ì´í„° ìƒì„± ë° ë¶„ì„")
    print("="*60)

    # ë°ì´í„° ìƒì„± ë° ì €ì¥
    demand_df, policy_df, market_df = generate_and_save_data()

    # ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”
    quick_analysis_and_visualization(demand_df, policy_df, market_df)

    # ê°„ë‹¨í•œ ëª¨ë¸ í•™ìŠµ
    build_and_train_simple_model(demand_df)

    # ì™„ë£Œ
    end_time = datetime.now()
    elapsed_time = (end_time - start_time).total_seconds()

    print("\n" + "="*60)
    print("âœ¨ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("="*60)

    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:")
    print("   [êµìœ¡ìš© ì‹œê°í™”]")
    print("   - visualizations/neural_networks_demo.png")
    print("   - visualizations/time_series_demo.png")
    print("   - visualizations/lstm_gru_comparison.png")

    print("\n   [ë°ì´í„° íŒŒì¼]")
    print("   - data/energy_demand.csv")
    print("   - data/renewable_policy.csv")
    print("   - data/electricity_market.csv")

    print("\n   [ë¶„ì„ ê²°ê³¼]")
    print("   - output/analysis_results.png")
    print("   - output/lstm_predictions.png")

    print(f"\nâ±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
    print("\ní”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()