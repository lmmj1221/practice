#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì œ5ì¥: ì„¤ëª…ê°€ëŠ¥í•œ AI êµ¬í˜„
SHAPê³¼ LIMEì„ í™œìš©í•œ ëª¨ë¸ ì„¤ëª…ê°€ëŠ¥ì„± í™•ë³´
"""

import numpy as np
import pandas as pd
import shap
import lime
import lime.lime_tabular
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif platform.system() == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

class ExplainabilityImplementation:
    """ì„¤ëª…ê°€ëŠ¥í•œ AI êµ¬í˜„ í´ë˜ìŠ¤"""

    def __init__(self, random_state=42):
        """
        ì„¤ëª…ê°€ëŠ¥ì„± êµ¬í˜„ ì´ˆê¸°í™”

        Parameters:
        random_state (int): ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
        """
        self.random_state = random_state
        self.model = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.feature_names = None
        self.shap_explainer = None
        self.lime_explainer = None
        self.scaler = StandardScaler()

    def generate_policy_explanation_data(self, n_samples=1000):
        """
        ì •ì±… ì„¤ëª…ì„ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        â€» ë³¸ ë°ì´í„°ëŠ” êµìœ¡ ëª©ì ì˜ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì…ë‹ˆë‹¤

        Parameters:
        n_samples (int): ìƒ˜í”Œ ìˆ˜

        Returns:
        tuple: (X, y, feature_names) íŠ¹ì„±, íƒ€ê²Ÿ, íŠ¹ì„±ëª…
        """
        np.random.seed(self.random_state)

        # ì •ì±… ê´€ë ¨ íŠ¹ì„± ì •ì˜
        feature_names = [
            'ê²½ì œì„±ì¥ë¥ (%)', 'ì‹¤ì—…ë¥ (%)', 'ì¸í”Œë ˆì´ì…˜ìœ¨(%)',
            'ì •ë¶€ì§€ì¶œë¹„ìœ¨(%)', 'êµìœ¡ì˜ˆì‚°ë¹„ìœ¨(%)', 'ì¸í”„ë¼íˆ¬ìë¹„ìœ¨(%)',
            'í˜ì‹ íˆ¬ìë¹„ìœ¨(%)', 'ì‚¬íšŒë³´ì¥ë¹„ìœ¨(%)', 'ì¸êµ¬ì¦ê°€ìœ¨(%)', 'ë„ì‹œí™”ìœ¨(%)'
        ]

        self.feature_names = feature_names
        n_features = len(feature_names)

        # íŠ¹ì„±ë³„ ë°ì´í„° ìƒì„± (ì‹¤ì œ ì •ì±… ë°ì´í„° ë¶„í¬ ëª¨ë°©)
        X = np.zeros((n_samples, n_features))

        # ê²½ì œì„±ì¥ë¥ : ì •ê·œë¶„í¬ (í‰ê·  2.5%, í‘œì¤€í¸ì°¨ 1.5%)
        X[:, 0] = np.random.normal(2.5, 1.5, n_samples)

        # ì‹¤ì—…ë¥ : ë¡œê·¸ì •ê·œë¶„í¬ (í‰ê·  4%, ìµœì†Œ 1%)
        X[:, 1] = np.maximum(1.0, np.random.lognormal(1.2, 0.3, n_samples))

        # ì¸í”Œë ˆì´ì…˜ìœ¨: ì •ê·œë¶„í¬ (í‰ê·  2%, í‘œì¤€í¸ì°¨ 1%)
        X[:, 2] = np.random.normal(2.0, 1.0, n_samples)

        # ì •ë¶€ì§€ì¶œë¹„ìœ¨: ê· ë“±ë¶„í¬ (15-30%)
        X[:, 3] = np.random.uniform(15, 30, n_samples)

        # êµìœ¡ì˜ˆì‚°ë¹„ìœ¨: ê°ë§ˆë¶„í¬ (í‰ê·  4%)
        X[:, 4] = np.random.gamma(2, 2, n_samples)

        # ì¸í”„ë¼íˆ¬ìë¹„ìœ¨: ì§€ìˆ˜ë¶„í¬ (í‰ê·  3%)
        X[:, 5] = np.random.exponential(3, n_samples)

        # í˜ì‹ íˆ¬ìë¹„ìœ¨: ë² íƒ€ë¶„í¬ (0-5% ë²”ìœ„)
        X[:, 6] = np.random.beta(2, 5, n_samples) * 5

        # ì‚¬íšŒë³´ì¥ë¹„ìœ¨: ì •ê·œë¶„í¬ (í‰ê·  8%, í‘œì¤€í¸ì°¨ 2%)
        X[:, 7] = np.random.normal(8, 2, n_samples)

        # ì¸êµ¬ì¦ê°€ìœ¨: ì •ê·œë¶„í¬ (í‰ê·  0.5%, í‘œì¤€í¸ì°¨ 0.3%)
        X[:, 8] = np.random.normal(0.5, 0.3, n_samples)

        # ë„ì‹œí™”ìœ¨: ë² íƒ€ë¶„í¬ (40-90% ë²”ìœ„)
        X[:, 9] = 40 + np.random.beta(2, 2, n_samples) * 50

        # ë³µì¡í•œ ì •ì±… íš¨ê³¼ í•¨ìˆ˜ ì •ì˜
        # ì •ì±…ë§Œì¡±ë„ = f(ê²½ì œì  ìš”ì¸, ì‚¬íšŒì  ìš”ì¸, êµ¬ì¡°ì  ìš”ì¸)
        y = self._calculate_policy_satisfaction(X)

        # DataFrame ìƒì„±
        X_df = pd.DataFrame(X, columns=feature_names)

        print(f"âœ… ì •ì±… ì„¤ëª…ìš© ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print(f"   - ìƒ˜í”Œ ìˆ˜: {n_samples}")
        print(f"   - íŠ¹ì„± ìˆ˜: {n_features}")
        print(f"   - ì •ì±…ë§Œì¡±ë„ ë²”ìœ„: [{y.min():.2f}, {y.max():.2f}]")

        return X_df, y, feature_names

    def _calculate_policy_satisfaction(self, X):
        """
        ë³µì¡í•œ ì •ì±… ë§Œì¡±ë„ ê³„ì‚° í•¨ìˆ˜

        Parameters:
        X (array): ì…ë ¥ íŠ¹ì„±

        Returns:
        array: ì •ì±… ë§Œì¡±ë„ ì ìˆ˜
        """
        # ê²½ì œì  ìš”ì¸ (ê°€ì¤‘ í‰ê· )
        economic_factor = (
            0.4 * X[:, 0] +                    # ê²½ì œì„±ì¥ë¥  (+)
            -0.3 * X[:, 1] +                   # ì‹¤ì—…ë¥  (-)
            -0.2 * np.power(X[:, 2], 2) +      # ì¸í”Œë ˆì´ì…˜ìœ¨ ì œê³± (-)
            0.1 * X[:, 3]                      # ì •ë¶€ì§€ì¶œë¹„ìœ¨ (+)
        )

        # ì‚¬íšŒì  ìš”ì¸
        social_factor = (
            0.3 * X[:, 4] +                    # êµìœ¡ì˜ˆì‚°ë¹„ìœ¨ (+)
            0.2 * np.log(X[:, 5] + 1) +        # ì¸í”„ë¼íˆ¬ìë¹„ìœ¨ ë¡œê·¸ (+)
            0.4 * X[:, 6] +                    # í˜ì‹ íˆ¬ìë¹„ìœ¨ (+)
            0.25 * X[:, 7]                     # ì‚¬íšŒë³´ì¥ë¹„ìœ¨ (+)
        )

        # êµ¬ì¡°ì  ìš”ì¸
        structural_factor = (
            0.2 * X[:, 8] +                    # ì¸êµ¬ì¦ê°€ìœ¨ (+)
            0.1 * np.power(X[:, 9] / 100, 0.5) # ë„ì‹œí™”ìœ¨ ì œê³±ê·¼ (+)
        )

        # ìƒí˜¸ì‘ìš© íš¨ê³¼
        interaction_effects = (
            0.05 * X[:, 0] * X[:, 4] +         # ê²½ì œì„±ì¥-êµìœ¡ ìƒí˜¸ì‘ìš©
            -0.03 * X[:, 1] * X[:, 2] +        # ì‹¤ì—…-ì¸í”Œë ˆì´ì…˜ ìƒí˜¸ì‘ìš©
            0.02 * X[:, 3] * X[:, 7] +         # ì •ë¶€ì§€ì¶œ-ì‚¬íšŒë³´ì¥ ìƒí˜¸ì‘ìš©
            0.01 * X[:, 5] * X[:, 9] / 100     # ì¸í”„ë¼-ë„ì‹œí™” ìƒí˜¸ì‘ìš©
        )

        # ìµœì¢… ì •ì±… ë§Œì¡±ë„ (0-100 ì  ìŠ¤ì¼€ì¼)
        satisfaction = (
            50 +                               # ê¸°ì¤€ì 
            economic_factor +
            social_factor +
            structural_factor +
            interaction_effects +
            0.5 * np.random.randn(len(X))      # ë…¸ì´ì¦ˆ
        )

        # 0-100 ë²”ìœ„ë¡œ í´ë¦¬í•‘
        satisfaction = np.clip(satisfaction, 0, 100)

        return satisfaction

    def prepare_data(self, X, y, test_size=0.2):
        """
        ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• 

        Parameters:
        X (DataFrame): ì…ë ¥ íŠ¹ì„±
        y (array): íƒ€ê²Ÿ ë³€ìˆ˜
        test_size (float): í…ŒìŠ¤íŠ¸ í¬ê¸° ë¹„ìœ¨

        Returns:
        tuple: ì „ì²˜ë¦¬ëœ ë°ì´í„°
        """
        # ë°ì´í„° ë¶„í• 
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )

        print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
        print(f"   - í•™ìŠµ ë°ì´í„°: {self.X_train.shape}")
        print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {self.X_test.shape}")

        return self.X_train, self.X_test, self.y_train, self.y_test

    def train_model(self, model_type='random_forest'):
        """
        ì„¤ëª… ê°€ëŠ¥í•œ ëª¨ë¸ í•™ìŠµ

        Parameters:
        model_type (str): ëª¨ë¸ íƒ€ì…

        Returns:
        object: í•™ìŠµëœ ëª¨ë¸
        """
        if model_type == 'random_forest':
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                random_state=self.random_state,
                n_jobs=-1
            )
        elif model_type == 'gradient_boosting':
            self.model = GradientBoostingRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=self.random_state
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")

        # ëª¨ë¸ í•™ìŠµ
        self.model.fit(self.X_train, self.y_train)

        # ì„±ëŠ¥ í‰ê°€
        train_pred = self.model.predict(self.X_train)
        test_pred = self.model.predict(self.X_test)

        train_r2 = r2_score(self.y_train, train_pred)
        test_r2 = r2_score(self.y_test, test_pred)

        print(f"âœ… {model_type} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        print(f"   - í•™ìŠµ RÂ²: {train_r2:.4f}")
        print(f"   - í…ŒìŠ¤íŠ¸ RÂ²: {test_r2:.4f}")

        return self.model

    def setup_shap_explainer(self, explainer_type='tree'):
        """
        SHAP ì„¤ëª…ê¸° ì„¤ì •

        Parameters:
        explainer_type (str): ì„¤ëª…ê¸° íƒ€ì…

        Returns:
        object: SHAP ì„¤ëª…ê¸°
        """
        if explainer_type == 'tree':
            self.shap_explainer = shap.TreeExplainer(self.model)
        elif explainer_type == 'kernel':
            # ì»¤ë„ ì„¤ëª…ê¸°ëŠ” ìƒ˜í”Œë§ëœ ë°°ê²½ ë°ì´í„° ì‚¬ìš©
            background = shap.sample(self.X_train, 100)
            self.shap_explainer = shap.KernelExplainer(self.model.predict, background)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„¤ëª…ê¸° íƒ€ì…: {explainer_type}")

        print(f"âœ… SHAP {explainer_type} ì„¤ëª…ê¸° ì„¤ì • ì™„ë£Œ")

        return self.shap_explainer

    def generate_shap_explanations(self, X_explain=None, max_display=10):
        """
        SHAP ì„¤ëª… ìƒì„±

        Parameters:
        X_explain (DataFrame): ì„¤ëª…í•  ë°ì´í„° (Noneì´ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©)
        max_display (int): í‘œì‹œí•  ìµœëŒ€ íŠ¹ì„± ìˆ˜

        Returns:
        array: SHAP ê°’
        """
        if X_explain is None:
            X_explain = self.X_test.head(100)  # ì²˜ìŒ 100ê°œ ìƒ˜í”Œ ì‚¬ìš©

        # SHAP ê°’ ê³„ì‚°
        shap_values = self.shap_explainer.shap_values(X_explain)

        print(f"âœ… SHAP ê°’ ê³„ì‚° ì™„ë£Œ: {shap_values.shape}")

        # 1. Summary Plot
        plt.figure(figsize=(12, 8))
        shap.summary_plot(
            shap_values, X_explain,
            feature_names=self.feature_names,
            max_display=max_display,
            show=False
        )
        plt.title('SHAP Summary Plot - íŠ¹ì„± ì¤‘ìš”ë„ì™€ ì˜í–¥ ë°©í–¥')
        plt.tight_layout()
        plt.savefig('c:/practice/chap/chapter05/outputs/shap_summary.png', dpi=300, bbox_inches='tight')
        plt.show()

        # 2. Feature Importance Bar Plot
        plt.figure(figsize=(10, 6))
        shap.summary_plot(
            shap_values, X_explain,
            feature_names=self.feature_names,
            plot_type='bar',
            max_display=max_display,
            show=False
        )
        plt.title('SHAP Feature Importance - íŠ¹ì„±ë³„ í‰ê·  ì ˆëŒ€ ê¸°ì—¬ë„')
        plt.tight_layout()
        plt.savefig('c:/practice/chap/chapter05/outputs/shap_importance.png', dpi=300, bbox_inches='tight')
        plt.show()

        # 3. Waterfall Plot (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
        if len(X_explain) > 0:
            plt.figure(figsize=(10, 8))
            shap.waterfall_plot(
                shap.Explanation(
                    values=shap_values[0],
                    base_values=self.shap_explainer.expected_value,
                    data=X_explain.iloc[0],
                    feature_names=self.feature_names
                ),
                max_display=max_display,
                show=False
            )
            plt.title('SHAP Waterfall Plot - ê°œë³„ ì˜ˆì¸¡ ì„¤ëª…')
            plt.tight_layout()
            plt.savefig('c:/practice/chap/chapter05/outputs/shap_waterfall.png', dpi=300, bbox_inches='tight')
            plt.show()

        # 4. Dependence Plot (ìƒìœ„ 2ê°œ íŠ¹ì„±)
        important_features = np.argsort(np.abs(shap_values).mean(0))[-2:]

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        for i, feature_idx in enumerate(important_features):
            plt.sca(axes[i])
            shap.dependence_plot(
                feature_idx, shap_values, X_explain,
                feature_names=self.feature_names,
                show=False
            )

        plt.tight_layout()
        plt.savefig('c:/practice/chap/chapter05/outputs/shap_dependence.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("ğŸ“Š SHAP ì‹œê°í™” ì™„ë£Œ:")
        print("   - Summary Plot: practice/chapter05/outputs/shap_summary.png")
        print("   - Feature Importance: practice/chapter05/outputs/shap_importance.png")
        print("   - Waterfall Plot: practice/chapter05/outputs/shap_waterfall.png")
        print("   - Dependence Plot: practice/chapter05/outputs/shap_dependence.png")

        return shap_values

    def setup_lime_explainer(self):
        """
        LIME ì„¤ëª…ê¸° ì„¤ì •

        Returns:
        object: LIME ì„¤ëª…ê¸°
        """
        self.lime_explainer = lime.lime_tabular.LimeTabularExplainer(
            self.X_train.values,
            feature_names=self.feature_names,
            mode='regression',
            discretize_continuous=True,
            random_state=self.random_state
        )

        print("âœ… LIME ì„¤ëª…ê¸° ì„¤ì • ì™„ë£Œ")

        return self.lime_explainer

    def generate_lime_explanations(self, instance_idx=0, num_features=10):
        """
        LIME ì„¤ëª… ìƒì„±

        Parameters:
        instance_idx (int): ì„¤ëª…í•  ì¸ìŠ¤í„´ìŠ¤ ì¸ë±ìŠ¤
        num_features (int): í‘œì‹œí•  íŠ¹ì„± ìˆ˜

        Returns:
        object: LIME ì„¤ëª… ê°ì²´
        """
        # ì„¤ëª…í•  ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ
        instance = self.X_test.iloc[instance_idx]
        actual_value = self.y_test[instance_idx]
        predicted_value = self.model.predict([instance.values])[0]

        # LIME ì„¤ëª… ìƒì„±
        explanation = self.lime_explainer.explain_instance(
            instance.values,
            self.model.predict,
            num_features=num_features,
            num_samples=1000
        )

        print(f"âœ… LIME ì„¤ëª… ìƒì„± ì™„ë£Œ (ì¸ìŠ¤í„´ìŠ¤ {instance_idx})")
        print(f"   - ì‹¤ì œ ê°’: {actual_value:.2f}")
        print(f"   - ì˜ˆì¸¡ ê°’: {predicted_value:.2f}")

        # ì„¤ëª… ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ¯ LIME íŠ¹ì„± ê¸°ì—¬ë„ (ìƒìœ„ {num_features}ê°œ):")
        print("-" * 50)

        feature_importance = explanation.as_list()
        for feature, importance in feature_importance:
            direction = "ì¦ê°€" if importance > 0 else "ê°ì†Œ"
            print(f"  {feature}: {importance:+.3f} ({direction})")

        # HTML ì„¤ëª… ì €ì¥
        explanation.save_to_file('c:/practice/chap/chapter05/outputs/lime_explanation.html')

        # ì‹œê°í™” ìƒì„±
        fig = explanation.as_pyplot_figure()
        fig.suptitle(f'LIME ì„¤ëª… - ì¸ìŠ¤í„´ìŠ¤ {instance_idx}')
        plt.tight_layout()
        plt.savefig('c:/practice/chap/chapter05/outputs/lime_explanation.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("ğŸ“Š LIME ì‹œê°í™” ì™„ë£Œ:")
        print("   - HTML ì„¤ëª…: practice/chapter05/outputs/lime_explanation.html")
        print("   - PNG ì´ë¯¸ì§€: practice/chapter05/outputs/lime_explanation.png")

        return explanation

    def compare_explanations(self, shap_values, lime_explanation, instance_idx=0):
        """
        SHAPê³¼ LIME ì„¤ëª… ë¹„êµ

        Parameters:
        shap_values (array): SHAP ê°’
        lime_explanation (object): LIME ì„¤ëª… ê°ì²´
        instance_idx (int): ë¹„êµí•  ì¸ìŠ¤í„´ìŠ¤ ì¸ë±ìŠ¤

        Returns:
        DataFrame: ë¹„êµ ê²°ê³¼
        """
        # SHAP ê°’ ì¶”ì¶œ (í•´ë‹¹ ì¸ìŠ¤í„´ìŠ¤)
        shap_instance = shap_values[instance_idx]

        # LIME ê°’ ì¶”ì¶œ
        lime_dict = dict(lime_explanation.as_list())

        # ë¹„êµ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        comparison_data = []

        for i, feature_name in enumerate(self.feature_names):
            shap_value = shap_instance[i]

            # LIME ê°’ ì°¾ê¸° (íŠ¹ì„±ëª…ì´ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            lime_value = 0
            for lime_feature, lime_val in lime_dict.items():
                if feature_name in lime_feature or lime_feature in feature_name:
                    lime_value = lime_val
                    break

            comparison_data.append({
                'íŠ¹ì„±': feature_name,
                'SHAP': shap_value,
                'LIME': lime_value,
                'ì°¨ì´': abs(shap_value - lime_value),
                'ë°©í–¥ì¼ì¹˜': (shap_value > 0) == (lime_value > 0)
            })

        comparison_df = pd.DataFrame(comparison_data)

        print(f"\nğŸ“Š SHAP vs LIME ì„¤ëª… ë¹„êµ (ì¸ìŠ¤í„´ìŠ¤ {instance_idx}):")
        print("="*60)
        print(comparison_df.to_string(index=False, float_format='%.3f'))

        # ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation = np.corrcoef(comparison_df['SHAP'], comparison_df['LIME'])[0, 1]
        agreement_rate = comparison_df['ë°©í–¥ì¼ì¹˜'].mean() * 100

        print(f"\nğŸ“ˆ ì¼ì¹˜ë„ ë¶„ì„:")
        print(f"   - ìƒê´€ê³„ìˆ˜: {correlation:.3f}")
        print(f"   - ë°©í–¥ ì¼ì¹˜ìœ¨: {agreement_rate:.1f}%")

        # ë¹„êµ ì‹œê°í™”
        plt.figure(figsize=(12, 5))

        # ì„œë¸Œí”Œë¡¯ 1: ê°’ ë¹„êµ
        plt.subplot(1, 2, 1)
        x_pos = np.arange(len(self.feature_names))
        width = 0.35

        plt.bar(x_pos - width/2, comparison_df['SHAP'], width, label='SHAP', alpha=0.8)
        plt.bar(x_pos + width/2, comparison_df['LIME'], width, label='LIME', alpha=0.8)

        plt.xlabel('íŠ¹ì„±')
        plt.ylabel('ê¸°ì—¬ë„')
        plt.title('SHAP vs LIME íŠ¹ì„± ê¸°ì—¬ë„ ë¹„êµ')
        plt.xticks(x_pos, self.feature_names, rotation=45, ha='right')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # ì„œë¸Œí”Œë¡¯ 2: ì‚°ì ë„
        plt.subplot(1, 2, 2)
        plt.scatter(comparison_df['SHAP'], comparison_df['LIME'], alpha=0.7, s=50)
        plt.xlabel('SHAP ê°’')
        plt.ylabel('LIME ê°’')
        plt.title(f'ìƒê´€ê´€ê³„ (r = {correlation:.3f})')

        # ëŒ€ê°ì„  ê·¸ë¦¬ê¸°
        min_val = min(comparison_df['SHAP'].min(), comparison_df['LIME'].min())
        max_val = max(comparison_df['SHAP'].max(), comparison_df['LIME'].max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.7)

        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('c:/practice/chap/chapter05/outputs/shap_lime_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("ğŸ“ˆ ë¹„êµ ì‹œê°í™” ì €ì¥: practice/chapter05/outputs/shap_lime_comparison.png")

        return comparison_df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì„¤ëª…ê°€ëŠ¥í•œ AI êµ¬í˜„ ì‹œì‘")
    print("="*60)

    # ì„¤ëª…ê°€ëŠ¥ì„± êµ¬í˜„ ê°ì²´ ìƒì„±
    explainer = ExplainabilityImplementation()

    # 1. ë°ì´í„° ìƒì„±
    print("\nğŸ“‹ 1ë‹¨ê³„: ì •ì±… ì„¤ëª…ìš© ë°ì´í„° ìƒì„±")
    X, y, feature_names = explainer.generate_policy_explanation_data(n_samples=1000)

    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    print("\nâš™ï¸ 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
    explainer.prepare_data(X, y, test_size=0.2)

    # 3. ëª¨ë¸ í•™ìŠµ
    print("\nğŸ¤– 3ë‹¨ê³„: Random Forest ëª¨ë¸ í•™ìŠµ")
    explainer.train_model(model_type='random_forest')

    # 4. SHAP ì„¤ëª… ìƒì„±
    print("\nğŸ” 4ë‹¨ê³„: SHAP ì„¤ëª… ìƒì„±")
    explainer.setup_shap_explainer(explainer_type='tree')
    shap_values = explainer.generate_shap_explanations(max_display=10)

    # 5. LIME ì„¤ëª… ìƒì„±
    print("\nğŸ” 5ë‹¨ê³„: LIME ì„¤ëª… ìƒì„±")
    explainer.setup_lime_explainer()
    lime_explanation = explainer.generate_lime_explanations(instance_idx=0, num_features=10)

    # 6. SHAPê³¼ LIME ë¹„êµ
    print("\nğŸ“Š 6ë‹¨ê³„: SHAP vs LIME ì„¤ëª… ë¹„êµ")
    comparison_results = explainer.compare_explanations(
        shap_values, lime_explanation, instance_idx=0
    )

    # 7. ì¶”ê°€ ë¶„ì„: ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ LIME ì„¤ëª…
    print("\nğŸ” 7ë‹¨ê³„: ì¶”ê°€ LIME ë¶„ì„")
    for i in [1, 2, 3]:
        print(f"\n   ğŸ“Œ ì¸ìŠ¤í„´ìŠ¤ {i} LIME ë¶„ì„:")
        explainer.generate_lime_explanations(instance_idx=i, num_features=5)

    # 8. ìµœì¢… ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ¯ ì„¤ëª…ê°€ëŠ¥í•œ AI êµ¬í˜„ ì™„ë£Œ!")
    print("="*60)

    # ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½
    test_pred = explainer.model.predict(explainer.X_test)
    test_r2 = r2_score(explainer.y_test, test_pred)
    test_rmse = np.sqrt(mean_squared_error(explainer.y_test, test_pred))

    print(f"ğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   - RÂ²: {test_r2:.4f}")
    print(f"   - RMSE: {test_rmse:.4f}")

    print(f"\nğŸ” ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„:")
    print(f"   - SHAP ë¶„ì„ ì™„ë£Œ: {shap_values.shape[0]}ê°œ ì¸ìŠ¤í„´ìŠ¤")
    print(f"   - LIME ë¶„ì„ ì™„ë£Œ: 4ê°œ ì¸ìŠ¤í„´ìŠ¤")
    print(f"   - SHAP-LIME ìƒê´€ê³„ìˆ˜: {np.corrcoef(comparison_results['SHAP'], comparison_results['LIME'])[0,1]:.3f}")

    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print("   - practice/chapter05/outputs/shap_summary.png")
    print("   - practice/chapter05/outputs/shap_importance.png")
    print("   - practice/chapter05/outputs/shap_waterfall.png")
    print("   - practice/chapter05/outputs/shap_dependence.png")
    print("   - practice/chapter05/outputs/lime_explanation.html")
    print("   - practice/chapter05/outputs/lime_explanation.png")
    print("   - practice/chapter05/outputs/shap_lime_comparison.png")

    print("\nâœ… ëª¨ë“  ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()