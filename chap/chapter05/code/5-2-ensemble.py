#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì œ5ì¥: ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„
XGBoostì™€ Random Forestë¥¼ ê²°í•©í•œ Voting Regressor êµ¬í˜„
"""

import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor, VotingRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Arial'
plt.rcParams['font.size'] = 10

class EnsembleModelImplementation:
    """ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„ í´ë˜ìŠ¤"""

    def __init__(self, random_state=42):
        """
        ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”

        Parameters:
        random_state (int): ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
        """
        self.random_state = random_state
        self.models = {}
        self.ensemble = None
        self.scaler = StandardScaler()
        self.best_params = {}

    def generate_policy_data(self, n_samples=1500, n_features=8):
        """
        ì •ì±… ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        â€» ë³¸ ë°ì´í„°ëŠ” êµìœ¡ ëª©ì ì˜ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì…ë‹ˆë‹¤

        Parameters:
        n_samples (int): ìƒ˜í”Œ ìˆ˜
        n_features (int): íŠ¹ì„± ìˆ˜

        Returns:
        tuple: (X, y, feature_names) íŠ¹ì„±, íƒ€ê²Ÿ, íŠ¹ì„±ëª…
        """
        np.random.seed(self.random_state)

        # ì •ì±… ê´€ë ¨ íŠ¹ì„± ìƒì„±
        feature_names = [
            'GDP Growth', 'Unemployment', 'Inflation', 'Gov Spending',
            'Population Density', 'Education Index', 'Infrastructure', 'Tech Innovation'
        ]

        # ë‹¤ì–‘í•œ ë¶„í¬ì—ì„œ íŠ¹ì„± ìƒì„±
        X = np.zeros((n_samples, n_features))
        X[:, 0] = np.random.normal(2.5, 1.0, n_samples)    # ê²½ì œì„±ì¥ë¥ 
        X[:, 1] = np.random.exponential(3.5, n_samples)    # ì‹¤ì—…ë¥ 
        X[:, 2] = np.random.normal(2.0, 0.8, n_samples)    # ì¸í”Œë ˆì´ì…˜ìœ¨
        X[:, 3] = np.random.uniform(15, 35, n_samples)     # ì •ë¶€ì§€ì¶œë¹„ìœ¨
        X[:, 4] = np.random.gamma(2, 2, n_samples)         # ì¸êµ¬ë°€ë„
        X[:, 5] = np.random.beta(2, 5, n_samples) * 100    # êµìœ¡ì§€ìˆ˜
        X[:, 6] = np.random.lognormal(3, 0.5, n_samples)   # ì¸í”„ë¼ì§€ìˆ˜
        X[:, 7] = np.random.weibull(2, n_samples) * 50     # ê¸°ìˆ í˜ì‹ ì§€ìˆ˜

        # ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ë¡œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        y = (0.8 * X[:, 0] +                               # ê²½ì œì„±ì¥ë¥  ì§ì ‘ íš¨ê³¼
             -0.5 * X[:, 1] +                              # ì‹¤ì—…ë¥  ì—­íš¨ê³¼
             -0.3 * X[:, 2] ** 2 +                         # ì¸í”Œë ˆì´ì…˜ ì œê³± íš¨ê³¼
             0.02 * X[:, 3] +                              # ì •ë¶€ì§€ì¶œ íš¨ê³¼
             0.1 * np.log(X[:, 4] + 1) +                   # ì¸êµ¬ë°€ë„ ë¡œê·¸ íš¨ê³¼
             0.05 * X[:, 5] +                              # êµìœ¡ íš¨ê³¼
             0.02 * X[:, 6] +                              # ì¸í”„ë¼ íš¨ê³¼
             0.03 * X[:, 7] +                              # ê¸°ìˆ í˜ì‹  íš¨ê³¼
             0.1 * X[:, 0] * X[:, 5] +                     # ê²½ì œì„±ì¥-êµìœ¡ ìƒí˜¸ì‘ìš©
             -0.05 * X[:, 1] * X[:, 2] +                   # ì‹¤ì—…-ì¸í”Œë ˆì´ì…˜ ìƒí˜¸ì‘ìš©
             0.5 * np.random.randn(n_samples))             # ë…¸ì´ì¦ˆ

        # DataFrameìœ¼ë¡œ ë³€í™˜
        X_df = pd.DataFrame(X, columns=feature_names)

        print(f"âœ… ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print(f"   - ìƒ˜í”Œ ìˆ˜: {n_samples}")
        print(f"   - íŠ¹ì„± ìˆ˜: {n_features}")
        print(f"   - íƒ€ê²Ÿ ë²”ìœ„: [{y.min():.2f}, {y.max():.2f}]")

        return X_df, y, feature_names

    def create_base_models(self):
        """
        ê¸°ë³¸ ëª¨ë¸ë“¤ ìƒì„±

        Returns:
        dict: ê¸°ë³¸ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        """
        # XGBoost ëª¨ë¸
        xgb_model = xgb.XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=self.random_state,
            n_jobs=-1
        )

        # Random Forest ëª¨ë¸
        rf_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=12,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=self.random_state,
            n_jobs=-1
        )

        # Gradient Boosting ëª¨ë¸
        gb_model = GradientBoostingRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            random_state=self.random_state
        )

        self.models = {
            'xgboost': xgb_model,
            'random_forest': rf_model,
            'gradient_boosting': gb_model
        }

        print("âœ… ê¸°ë³¸ ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        for name in self.models.keys():
            print(f"   - {name}")

        return self.models

    def optimize_hyperparameters(self, X_train, y_train, cv_folds=3):
        """
        í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

        Parameters:
        X_train, y_train: í•™ìŠµ ë°ì´í„°
        cv_folds (int): êµì°¨ê²€ì¦ í´ë“œ ìˆ˜

        Returns:
        dict: ìµœì í™”ëœ íŒŒë¼ë¯¸í„°
        """
        print("\nğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘...")

        # XGBoost íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        xgb_params = {
            'n_estimators': [50, 100],
            'max_depth': [4, 6, 8],
            'learning_rate': [0.05, 0.1, 0.15]
        }

        # Random Forest íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        rf_params = {
            'n_estimators': [50, 100],
            'max_depth': [8, 12, 16],
            'min_samples_split': [2, 5]
        }

        param_grids = {
            'xgboost': xgb_params,
            'random_forest': rf_params
        }

        for name, model in list(self.models.items())[:2]:  # XGBoost, RFë§Œ ìµœì í™”
            if name in param_grids:
                print(f"   ğŸ”„ {name} ìµœì í™” ì¤‘...")

                grid_search = GridSearchCV(
                    model,
                    param_grids[name],
                    cv=cv_folds,
                    scoring='neg_mean_squared_error',
                    n_jobs=-1,
                    verbose=0
                )

                grid_search.fit(X_train, y_train)

                self.best_params[name] = grid_search.best_params_
                self.models[name] = grid_search.best_estimator_

                print(f"   âœ… {name} ìµœì í™” ì™„ë£Œ")
                print(f"      ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")

        return self.best_params

    def create_voting_ensemble(self, weights=None):
        """
        Voting Regressor ìƒì„±

        Parameters:
        weights (list): ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜

        Returns:
        VotingRegressor: ì•™ìƒë¸” ëª¨ë¸
        """
        estimators = [(name, model) for name, model in self.models.items()]

        self.ensemble = VotingRegressor(
            estimators=estimators,
            weights=weights
        )

        print("âœ… Voting Regressor ìƒì„± ì™„ë£Œ")
        print(f"   - êµ¬ì„± ëª¨ë¸: {len(estimators)}ê°œ")
        if weights:
            print(f"   - ê°€ì¤‘ì¹˜: {weights}")

        return self.ensemble

    def train_models(self, X_train, y_train):
        """
        ëª¨ë“  ëª¨ë¸ í•™ìŠµ

        Parameters:
        X_train, y_train: í•™ìŠµ ë°ì´í„°

        Returns:
        dict: í•™ìŠµëœ ëª¨ë¸ë“¤
        """
        print("\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

        # ê°œë³„ ëª¨ë¸ í•™ìŠµ
        for name, model in self.models.items():
            print(f"   ğŸ”„ {name} í•™ìŠµ ì¤‘...")
            model.fit(X_train, y_train)
            print(f"   âœ… {name} í•™ìŠµ ì™„ë£Œ")

        # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
        if self.ensemble is not None:
            print("   ğŸ”„ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘...")
            self.ensemble.fit(X_train, y_train)
            print("   âœ… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

        print("ğŸ¯ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

        return self.models

    def evaluate_models(self, X_test, y_test):
        """
        ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

        Parameters:
        X_test, y_test: í…ŒìŠ¤íŠ¸ ë°ì´í„°

        Returns:
        dict: í‰ê°€ ê²°ê³¼
        """
        results = {}

        print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...")

        # ê°œë³„ ëª¨ë¸ í‰ê°€
        for name, model in self.models.items():
            predictions = model.predict(X_test)

            mse = mean_squared_error(y_test, predictions)
            mae = mean_absolute_error(y_test, predictions)
            r2 = r2_score(y_test, predictions)

            results[name] = {
                'MSE': mse,
                'MAE': mae,
                'RMSE': np.sqrt(mse),
                'RÂ²': r2,
                'predictions': predictions
            }

            print(f"   âœ… {name}: MSE={mse:.4f}, MAE={mae:.4f}, RÂ²={r2:.4f}")

        # ì•™ìƒë¸” ëª¨ë¸ í‰ê°€
        if self.ensemble is not None:
            ensemble_pred = self.ensemble.predict(X_test)
            ensemble_mse = mean_squared_error(y_test, ensemble_pred)
            ensemble_mae = mean_absolute_error(y_test, ensemble_pred)
            ensemble_r2 = r2_score(y_test, ensemble_pred)

            results['ensemble'] = {
                'MSE': ensemble_mse,
                'MAE': ensemble_mae,
                'RMSE': np.sqrt(ensemble_mse),
                'RÂ²': ensemble_r2,
                'predictions': ensemble_pred
            }

            print(f"   âœ… ensemble: MSE={ensemble_mse:.4f}, MAE={ensemble_mae:.4f}, RÂ²={ensemble_r2:.4f}")

        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ!")

        return results

    def cross_validate_models(self, X, y, cv_folds=5):
        """
        êµì°¨ê²€ì¦ ìˆ˜í–‰

        Parameters:
        X, y: ì „ì²´ ë°ì´í„°
        cv_folds (int): êµì°¨ê²€ì¦ í´ë“œ ìˆ˜

        Returns:
        dict: êµì°¨ê²€ì¦ ê²°ê³¼
        """
        print(f"\nğŸ”„ {cv_folds}-fold êµì°¨ê²€ì¦ ì‹œì‘...")

        cv_results = {}

        for name, model in self.models.items():
            scores = cross_val_score(
                model, X, y,
                cv=cv_folds,
                scoring='neg_mean_squared_error'
            )

            cv_results[name] = {
                'mean_score': -scores.mean(),
                'std_score': scores.std(),
                'scores': -scores
            }

            print(f"   {name}: {-scores.mean():.4f} (Â±{scores.std():.4f})")

        # ì•™ìƒë¸” êµì°¨ê²€ì¦
        if self.ensemble is not None:
            ensemble_scores = cross_val_score(
                self.ensemble, X, y,
                cv=cv_folds,
                scoring='neg_mean_squared_error'
            )

            cv_results['ensemble'] = {
                'mean_score': -ensemble_scores.mean(),
                'std_score': ensemble_scores.std(),
                'scores': -ensemble_scores
            }

            print(f"   ensemble: {-ensemble_scores.mean():.4f} (Â±{ensemble_scores.std():.4f})")

        print("âœ… êµì°¨ê²€ì¦ ì™„ë£Œ!")

        return cv_results

    def plot_model_comparison(self, results, save_path='../outputs/ensemble_comparison.png'):
        """
        ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”

        Parameters:
        results (dict): í‰ê°€ ê²°ê³¼
        save_path (str): ì €ì¥ ê²½ë¡œ
        """
        # ë©”íŠ¸ë¦­ ì¶”ì¶œ
        models = list(results.keys())
        metrics = ['MSE', 'MAE', 'RMSE', 'RÂ²']

        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        axes = axes.ravel()

        for i, metric in enumerate(metrics):
            values = [results[model][metric] for model in models]

            bars = axes[i].bar(models, values, alpha=0.7, color=plt.cm.Set3(np.arange(len(models))))
            axes[i].set_title(f'{metric} Performance Comparison')
            axes[i].set_ylabel(metric)
            axes[i].tick_params(axis='x', rotation=45)

            # ê°’ í‘œì‹œ
            for bar, value in zip(bars, values):
                height = bar.get_height()
                axes[i].text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                           f'{value:.3f}', ha='center', va='bottom')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ ì €ì¥: {save_path}")

    def plot_prediction_comparison(self, y_test, results, save_path='../outputs/prediction_comparison.png'):
        """
        ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ì‹œê°í™”

        Parameters:
        y_test: ì‹¤ì œ ê°’
        results (dict): ì˜ˆì¸¡ ê²°ê³¼
        save_path (str): ì €ì¥ ê²½ë¡œ
        """
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        axes = axes.ravel()

        models = list(results.keys())

        for i, model_name in enumerate(models[:4]):  # ìµœëŒ€ 4ê°œ ëª¨ë¸
            predictions = results[model_name]['predictions']
            r2 = results[model_name]['RÂ²']

            axes[i].scatter(y_test, predictions, alpha=0.6, s=30)
            axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
            axes[i].set_xlabel('Actual Values')
            axes[i].set_ylabel('Predicted Values')
            axes[i].set_title(f'{model_name} (RÂ² = {r2:.3f})')
            axes[i].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"ğŸ“ˆ ì˜ˆì¸¡ ë¹„êµ ì°¨íŠ¸ ì €ì¥: {save_path}")

    def get_feature_importance(self, feature_names):
        """
        íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ

        Parameters:
        feature_names (list): íŠ¹ì„±ëª… ë¦¬ìŠ¤íŠ¸

        Returns:
        dict: ëª¨ë¸ë³„ íŠ¹ì„± ì¤‘ìš”ë„
        """
        importance_dict = {}

        for name, model in self.models.items():
            if hasattr(model, 'feature_importances_'):
                importance_dict[name] = dict(zip(feature_names, model.feature_importances_))

        return importance_dict

    def plot_feature_importance(self, feature_names, save_path='../outputs/feature_importance.png'):
        """
        íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”

        Parameters:
        feature_names (list): íŠ¹ì„±ëª… ë¦¬ìŠ¤íŠ¸
        save_path (str): ì €ì¥ ê²½ë¡œ
        """
        importance_dict = self.get_feature_importance(feature_names)

        if not importance_dict:
            print("âš ï¸ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        fig, axes = plt.subplots(1, len(importance_dict), figsize=(5*len(importance_dict), 6))

        if len(importance_dict) == 1:
            axes = [axes]

        for i, (model_name, importance) in enumerate(importance_dict.items()):
            features = list(importance.keys())
            values = list(importance.values())

            # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_idx = np.argsort(values)
            features = [features[i] for i in sorted_idx]
            values = [values[i] for i in sorted_idx]

            axes[i].barh(features, values, alpha=0.7)
            axes[i].set_title(f'{model_name} Feature Importance')
            axes[i].set_xlabel('Importance')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"ğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ ì°¨íŠ¸ ì €ì¥: {save_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„ ì‹œì‘")
    print("="*60)

    # ì•™ìƒë¸” êµ¬í˜„ ê°ì²´ ìƒì„±
    ensemble_impl = EnsembleModelImplementation()

    # 1. ë°ì´í„° ìƒì„±
    print("\nğŸ“‹ 1ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±")
    X, y, feature_names = ensemble_impl.generate_policy_data(n_samples=1500, n_features=8)

    # 2. ë°ì´í„° ë¶„í• 
    print("\nâš™ï¸ 2ë‹¨ê³„: ë°ì´í„° ë¶„í• ")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print(f"   - í•™ìŠµ ë°ì´í„°: {X_train.shape}")
    print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")

    # 3. ê¸°ë³¸ ëª¨ë¸ ìƒì„±
    print("\nğŸ¤– 3ë‹¨ê³„: ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
    ensemble_impl.create_base_models()

    # 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
    print("\nğŸ”§ 4ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”")
    ensemble_impl.optimize_hyperparameters(X_train, y_train, cv_folds=3)

    # 5. ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    print("\nğŸ¯ 5ë‹¨ê³„: ì•™ìƒë¸” ëª¨ë¸ ìƒì„±")
    ensemble_impl.create_voting_ensemble()

    # 6. ëª¨ë¸ í•™ìŠµ
    print("\nğŸš€ 6ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
    ensemble_impl.train_models(X_train, y_train)

    # 7. êµì°¨ê²€ì¦
    print("\nğŸ”„ 7ë‹¨ê³„: êµì°¨ê²€ì¦")
    cv_results = ensemble_impl.cross_validate_models(X, y, cv_folds=5)

    # 8. í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
    print("\nğŸ“Š 8ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€")
    test_results = ensemble_impl.evaluate_models(X_test, y_test)

    # 9. ê²°ê³¼ ì‹œê°í™”
    print("\nğŸ“ˆ 9ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™”")
    ensemble_impl.plot_model_comparison(test_results)
    ensemble_impl.plot_prediction_comparison(y_test, test_results)
    ensemble_impl.plot_feature_importance(feature_names)

    # 10. ìµœì¢… ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“Š ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ!")
    print("="*60)

    best_model = min(test_results.keys(), key=lambda x: test_results[x]['MSE'])
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
    print(f"   - MSE: {test_results[best_model]['MSE']:.4f}")
    print(f"   - RÂ²: {test_results[best_model]['RÂ²']:.4f}")

    if 'ensemble' in test_results:
        improvement = (test_results[best_model]['MSE'] - test_results['ensemble']['MSE']) / test_results[best_model]['MSE'] * 100
        if improvement > 0:
            print(f"ğŸ¯ ì•™ìƒë¸”ë¡œ ì¸í•œ ê°œì„ ìœ¨: {improvement:.1f}%")

    print("\nğŸ“ ìƒì„¸ ê²°ê³¼ëŠ” practice/chapter05/outputs/ í´ë”ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()