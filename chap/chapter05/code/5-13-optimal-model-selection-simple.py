"""
ìµœì  ëª¨ë¸ ì„ íƒ - ê°„ë‹¨ ì‹œì—° ë²„ì „
ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ìµœì í™”ëœ ë²„ì „
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
if platform.system() == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif platform.system() == 'Darwin':
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

def quick_model_selection_demo():
    """ë¹ ë¥¸ ëª¨ë¸ ì„ íƒ ì‹œì—°"""

    print("="*60)
    print("ğŸš€ ìµœì  ëª¨ë¸ ì„ íƒ í”„ë ˆì„ì›Œí¬ - ê°„ë‹¨ ì‹œì—°")
    print("="*60)

    # 1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 500
    n_features = 5

    # ì„ í˜• íŒ¨í„´ ë°ì´í„°
    X_linear = np.random.randn(n_samples, n_features)
    y_linear = 2*X_linear[:, 0] + 3*X_linear[:, 1] + np.random.randn(n_samples) * 0.1

    # ë¹„ì„ í˜• íŒ¨í„´ ë°ì´í„°
    X_nonlinear = np.random.randn(n_samples, n_features)
    y_nonlinear = np.sin(X_nonlinear[:, 0]) + X_nonlinear[:, 1]**2 + np.random.randn(n_samples) * 0.1

    # 2. ëª¨ë¸ ì •ì˜
    models = {
        'Linear Regression': {
            'model': LinearRegression(),
            'explainability': 1.0,
            'simplicity': 1.0
        },
        'Ridge Regression': {
            'model': Ridge(alpha=1.0),
            'explainability': 0.95,
            'simplicity': 0.95
        },
        'Random Forest': {
            'model': RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1),
            'explainability': 0.6,
            'simplicity': 0.4
        },
        'Gradient Boosting': {
            'model': GradientBoostingRegressor(n_estimators=50, random_state=42),
            'explainability': 0.5,
            'simplicity': 0.3
        }
    }

    # 3. ê°€ì¤‘ì¹˜ í”„ë¡œíŒŒì¼
    weight_profiles = {
        'ì„¤ëª…ë ¥ ìš°ì„ ': {'accuracy': 0.2, 'explainability': 0.4, 'simplicity': 0.2, 'speed': 0.1, 'robustness': 0.1},
        'ì˜ˆì¸¡ë ¥ ìš°ì„ ': {'accuracy': 0.5, 'explainability': 0.1, 'simplicity': 0.05, 'speed': 0.15, 'robustness': 0.2},
        'ê· í˜• ì¶”êµ¬': {'accuracy': 0.3, 'explainability': 0.3, 'simplicity': 0.15, 'speed': 0.1, 'robustness': 0.15}
    }

    results = []

    # 4. ëª¨ë¸ í‰ê°€
    print("\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ëª¨ë¸ ì„ íƒ")
    print("-"*60)

    scenarios = [
        ('ì„ í˜• íŒ¨í„´', X_linear, y_linear),
        ('ë¹„ì„ í˜• íŒ¨í„´', X_nonlinear, y_nonlinear)
    ]

    for scenario_name, X, y in scenarios:
        print(f"\nğŸ” {scenario_name} ë°ì´í„°")
        print("-"*40)

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        scenario_results = {}

        for profile_name, weights in weight_profiles.items():
            best_score = -1
            best_model = None

            for model_name, config in models.items():
                model = config['model']

                # ì •í™•ë„ í‰ê°€ (3-foldë¡œ ì¶•ì†Œ)
                scores = cross_val_score(model, X_scaled, y, cv=3, scoring='r2')
                accuracy = scores.mean()
                robustness = 1 - scores.std()

                # ì†ë„ ì ìˆ˜ (ë‹¨ìˆœí™”)
                import time
                start = time.time()
                model.fit(X_scaled, y)
                train_time = time.time() - start
                speed_score = 1 / (1 + train_time * 10)

                # ì¢…í•© ì ìˆ˜
                total_score = (
                    weights['accuracy'] * max(0, accuracy) +
                    weights['explainability'] * config['explainability'] +
                    weights['simplicity'] * config['simplicity'] +
                    weights['speed'] * speed_score +
                    weights['robustness'] * robustness
                )

                if total_score > best_score:
                    best_score = total_score
                    best_model = model_name
                    best_accuracy = accuracy

            scenario_results[profile_name] = {
                'model': best_model,
                'score': best_score,
                'accuracy': best_accuracy
            }

            print(f"  {profile_name:12} â†’ {best_model:20} (RÂ²={best_accuracy:.3f}, ì ìˆ˜={best_score:.3f})")

        results.append({
            'scenario': scenario_name,
            'results': scenario_results
        })

    # 5. íŒŒë ˆí†  ìµœì  ë¶„ì„
    print("\n" + "="*60)
    print("ğŸ¯ íŒŒë ˆí†  ìµœì  ëª¨ë¸ ë¶„ì„")
    print("-"*60)

    # ë§ˆì§€ë§‰ ì‹œë‚˜ë¦¬ì˜¤(ë¹„ì„ í˜•)ì— ëŒ€í•œ íŒŒë ˆí†  ë¶„ì„
    X, y = X_nonlinear, y_nonlinear
    X_scaled = scaler.fit_transform(X)

    model_performance = []
    for model_name, config in models.items():
        model = config['model']
        scores = cross_val_score(model, X_scaled, y, cv=3, scoring='r2')
        accuracy = scores.mean()

        model_performance.append({
            'name': model_name,
            'accuracy': max(0, accuracy),
            'explainability': config['explainability']
        })

    # íŒŒë ˆí†  ìµœì  ì°¾ê¸°
    pareto_optimal = []
    for i, model1 in enumerate(model_performance):
        is_dominated = False
        for j, model2 in enumerate(model_performance):
            if i == j:
                continue
            if (model2['accuracy'] > model1['accuracy'] and model2['explainability'] >= model1['explainability']) or \
               (model2['accuracy'] >= model1['accuracy'] and model2['explainability'] > model1['explainability']):
                is_dominated = True
                break

        if not is_dominated:
            pareto_optimal.append(model1['name'])
            print(f"âœ… {model1['name']:20} - ì •í™•ë„: {model1['accuracy']:.3f}, ì„¤ëª…ë ¥: {model1['explainability']:.2f}")

    # 6. ì‹œê°í™”
    create_visualization(model_performance, results)

    # 7. ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ’¡ í•µì‹¬ í†µì°°")
    print("-"*60)
    print("1. ì„ í˜• ë°ì´í„° â†’ Linear Regressionì´ ëª¨ë“  ëª©ì ì— ìµœì ")
    print("2. ë¹„ì„ í˜• ë°ì´í„° â†’ ëª©ì ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ë¸ ì„ íƒ")
    print("3. íŒŒë ˆí†  ìµœì  â†’ ì •í™•ë„-ì„¤ëª…ë ¥ trade-off ê³ ë ¤")
    print("="*60)

    return results

def create_visualization(model_performance, results):
    """ê²°ê³¼ ì‹œê°í™”"""

    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # 1. ì •í™•ë„ vs ì„¤ëª…ë ¥ ì‚°ì ë„
    accuracy = [m['accuracy'] for m in model_performance]
    explainability = [m['explainability'] for m in model_performance]
    names = [m['name'] for m in model_performance]

    axes[0].scatter(accuracy, explainability, s=200, alpha=0.6, c=range(len(names)), cmap='viridis')

    for i, name in enumerate(names):
        axes[0].annotate(name, (accuracy[i], explainability[i]),
                        fontsize=9, ha='center', va='bottom')

    axes[0].set_xlabel('ì •í™•ë„ (RÂ² Score)', fontsize=11)
    axes[0].set_ylabel('ì„¤ëª…ë ¥', fontsize=11)
    axes[0].set_title('ëª¨ë¸ë³„ ì •í™•ë„-ì„¤ëª…ë ¥ Trade-off', fontsize=12, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    axes[0].set_xlim(-0.1, 1.1)
    axes[0].set_ylim(-0.1, 1.1)

    # 2. ëª©ì ë³„ ìµœì  ëª¨ë¸ ë§‰ëŒ€ ê·¸ë˜í”„
    profiles = ['ì„¤ëª…ë ¥ ìš°ì„ ', 'ì˜ˆì¸¡ë ¥ ìš°ì„ ', 'ê· í˜• ì¶”êµ¬']
    linear_models = []
    nonlinear_models = []

    for result in results:
        if result['scenario'] == 'ì„ í˜• íŒ¨í„´':
            linear_models = [result['results'][p]['model'] for p in profiles]
        else:
            nonlinear_models = [result['results'][p]['model'] for p in profiles]

    x = np.arange(len(profiles))
    width = 0.35

    # ê° ëª¨ë¸ì„ ìˆ«ìë¡œ ë§¤í•‘í•˜ì—¬ ë§‰ëŒ€ ë†’ì´ë¡œ ì‚¬ìš©
    model_to_num = {'Linear Regression': 1, 'Ridge Regression': 2,
                    'Random Forest': 3, 'Gradient Boosting': 4}

    linear_nums = [model_to_num.get(m, 0) for m in linear_models]
    nonlinear_nums = [model_to_num.get(m, 0) for m in nonlinear_models]

    bars1 = axes[1].bar(x - width/2, linear_nums, width, label='ì„ í˜• íŒ¨í„´', alpha=0.8)
    bars2 = axes[1].bar(x + width/2, nonlinear_nums, width, label='ë¹„ì„ í˜• íŒ¨í„´', alpha=0.8)

    axes[1].set_xlabel('ëª©ì ', fontsize=11)
    axes[1].set_ylabel('ëª¨ë¸ ìœ í˜•', fontsize=11)
    axes[1].set_title('ëª©ì ë³„ ìµœì  ëª¨ë¸ ì„ íƒ', fontsize=12, fontweight='bold')
    axes[1].set_xticks(x)
    axes[1].set_xticklabels(profiles)
    axes[1].set_yticks([1, 2, 3, 4])
    axes[1].set_yticklabels(['Linear', 'Ridge', 'Random\nForest', 'Gradient\nBoosting'], fontsize=9)
    axes[1].legend()
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()

    # ì €ì¥
    output_dir = 'c:/practice/chap/chapter05/outputs'
    import os
    os.makedirs(output_dir, exist_ok=True)
    plt.savefig(f'{output_dir}/model_selection_simple.png', dpi=150, bbox_inches='tight')
    plt.show()

    print(f"\nğŸ“Š ì‹œê°í™”ê°€ {output_dir}/model_selection_simple.pngì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    results = quick_model_selection_demo()
    print("\nâœ… ëª¨ë¸ ì„ íƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")