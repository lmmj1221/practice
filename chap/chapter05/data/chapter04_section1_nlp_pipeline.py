"""
ì œ4ì¥ 4.1ì ˆ: NLP íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ë° ê¸°ë³¸ ê°œë… ì‹¤ìŠµ
ìì—°ì–´ ì²˜ë¦¬ì˜ ê¸°ë³¸ ê³¼ì •ì„ ì‹œê°í™”í•˜ê³  ì´í•´í•˜ê¸°
"""

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.patches import FancyBboxPatch
import numpy as np
import pandas as pd
from collections import Counter
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

def draw_nlp_pipeline():
    """NLP ì²˜ë¦¬ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì‹œê°í™”"""
    fig, ax = plt.subplots(figsize=(16, 10))
    
    # ë‹¨ê³„ë³„ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    stages = [
        ("ì…ë ¥ í…ìŠ¤íŠ¸\n'í™˜ê²½ ì •ì±…ì´ í•„ìš”í•´ìš”'", 1, '#FFE5B4'),
        ("í† í°í™”\n['í™˜ê²½', 'ì •ì±…', 'ì´', 'í•„ìš”', 'í•´ìš”']", 2, '#B4E5FF'),
        ("ë²¡í„° ë³€í™˜\n[[0.2, -0.5], [0.8, 0.3], ...]", 3, '#C8FFB4'),
        ("ëª¨ë¸ ì²˜ë¦¬\nBERT/GPT", 4, '#FFB4E5'),
        ("ê²°ê³¼ ì¶œë ¥\nì¹´í…Œê³ ë¦¬: í™˜ê²½", 5, '#E5B4FF')
    ]
    
    for i, (text, pos, color) in enumerate(stages):
        # ê° ë‹¨ê³„ë¥¼ ë°•ìŠ¤ë¡œ í‘œí˜„
        box = FancyBboxPatch((pos-0.4, 0.3), 0.8, 0.4,
                             boxstyle="round,pad=0.1",
                             facecolor=color, edgecolor='black', linewidth=2)
        ax.add_patch(box)
        ax.text(pos, 0.5, text, ha='center', va='center', fontsize=12, weight='bold')
        
        # í™”ì‚´í‘œ ê·¸ë¦¬ê¸°
        if i < len(stages) - 1:
            ax.arrow(pos + 0.5, 0.5, 0.4, 0, head_width=0.05, head_length=0.05, fc='gray', ec='gray')
    
    ax.set_xlim(0, 6)
    ax.set_ylim(0, 1)
    ax.axis('off')
    ax.set_title('ğŸ”„ NLP ì²˜ë¦¬ ê³¼ì • - í…ìŠ¤íŠ¸ê°€ ì»´í“¨í„° ì–¸ì–´ë¡œ ë³€í™˜ë˜ëŠ” ê³¼ì •', fontsize=16, weight='bold', pad=20)
    
    plt.tight_layout()
    plt.savefig('output/nlp_pipeline.png', dpi=300, bbox_inches='tight')
    plt.show()

def visualize_complaint_categories():
    """ë¯¼ì› ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ì‹œê°í™”"""
    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('../data/complaints_data.csv')
    
    # í•œêµ­ì–´ ë¯¼ì›ë§Œ í•„í„°ë§
    korean_df = df[df['language'] == 'ko']
    
    categories = korean_df['category'].value_counts()
    colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99', '#FF99CC']
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # ë§‰ëŒ€ ê·¸ë˜í”„
    bars = ax1.bar(categories.index, categories.values, color=colors, edgecolor='black', linewidth=1.5)
    ax1.set_title('ğŸ“Š í•œêµ­ ë¯¼ì› ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬', fontsize=14, weight='bold')
    ax1.set_xlabel('ì¹´í…Œê³ ë¦¬', fontsize=12)
    ax1.set_ylabel('ë¯¼ì› ìˆ˜', fontsize=12)
    ax1.grid(axis='y', alpha=0.3)
    
    # ê° ë§‰ëŒ€ ìœ„ì— ìˆ«ì í‘œì‹œ
    for bar, count in zip(bars, categories.values):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,
                f'{count}ê±´', ha='center', fontsize=11, weight='bold')
    
    # íŒŒì´ ì°¨íŠ¸
    explode = (0.1, 0, 0, 0, 0)  # ì²« ë²ˆì§¸ ì¡°ê° ê°•ì¡°
    ax2.pie(categories.values, labels=categories.index, colors=colors, autopct='%1.1f%%',
            startangle=90, explode=explode, shadow=True)
    ax2.set_title('ğŸ¥§ í•œêµ­ ë¯¼ì› ë¹„ìœ¨ ë¶„ì„', fontsize=14, weight='bold')
    
    plt.tight_layout()
    plt.savefig('../output/complaint_categories.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return categories

def compare_korean_english():
    """í•œêµ­ì–´ì™€ ì˜ì–´ ì²˜ë¦¬ ì°¨ì´ ì‹œê°í™”"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # ì˜ì–´ í† í°í™”
    ax1.text(0.5, 0.9, "ì˜ì–´: 'I love you'", ha='center', fontsize=16, weight='bold')
    eng_tokens = ['I', 'love', 'you']
    for i, token in enumerate(eng_tokens):
        rect = patches.Rectangle((0.2 + i*0.25, 0.5), 0.2, 0.2,
                                linewidth=2, edgecolor='blue', facecolor='lightblue')
        ax1.add_patch(rect)
        ax1.text(0.3 + i*0.25, 0.6, token, ha='center', va='center', fontsize=14, weight='bold')
    
    ax1.arrow(0.5, 0.4, 0, -0.15, head_width=0.05, head_length=0.03, fc='red', ec='red')
    ax1.text(0.5, 0.15, "3ê°œ í† í° (ë‹¨ìˆœ)", ha='center', fontsize=12, color='blue', weight='bold')
    
    ax1.set_xlim(0, 1)
    ax1.set_ylim(0, 1)
    ax1.axis('off')
    ax1.set_title('ğŸ”¤ ì˜ì–´ ì²˜ë¦¬', fontsize=15, weight='bold')
    
    # í•œêµ­ì–´ í† í°í™”
    ax2.text(0.5, 0.9, "í•œêµ­ì–´: 'ì‚¬ë‘í•´ìš”'", ha='center', fontsize=16, weight='bold')
    kor_tokens = ['ì‚¬ë‘', 'í•´', 'ìš”']
    kor_detail = ['ëª…ì‚¬', 'ë™ì‚¬', 'ì¡´ì¹­']
    
    for i, (token, detail) in enumerate(zip(kor_tokens, kor_detail)):
        rect = patches.Rectangle((0.2 + i*0.25, 0.5), 0.2, 0.2,
                                linewidth=2, edgecolor='red', facecolor='#FFE5E5')
        ax2.add_patch(rect)
        ax2.text(0.3 + i*0.25, 0.65, token, ha='center', va='center', fontsize=14, weight='bold')
        ax2.text(0.3 + i*0.25, 0.55, f'({detail})', ha='center', va='center', fontsize=10, style='italic')
    
    ax2.arrow(0.5, 0.4, 0, -0.15, head_width=0.05, head_length=0.03, fc='red', ec='red')
    ax2.text(0.5, 0.15, "í˜•íƒœì†Œ ë¶„ì„ í•„ìš” (ë³µì¡)", ha='center', fontsize=12, color='red', weight='bold')
    
    ax2.set_xlim(0, 1)
    ax2.set_ylim(0, 1)
    ax2.axis('off')
    ax2.set_title('ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì²˜ë¦¬', fontsize=15, weight='bold')
    
    plt.tight_layout()
    plt.savefig('../output/korean_vs_english_processing.png', dpi=300, bbox_inches='tight')
    plt.show()

def visualize_tokenization():
    """ë‹¤ì–‘í•œ í† í°í™” ë°©ì‹ ì‹œê°í™”"""
    sentence = "ì•ˆë…•í•˜ì„¸ìš”"
    
    tokenizations = {
        'ì›ë³¸': ['ì•ˆë…•í•˜ì„¸ìš”'],
        'ê¸€ì': ['ì•ˆ', 'ë…•', 'í•˜', 'ì„¸', 'ìš”'],
        'í˜•íƒœì†Œ': ['ì•ˆë…•', 'í•˜', 'ì„¸ìš”'],
        'ì„œë¸Œì›Œë“œ': ['ì•ˆë…•', '##í•˜ì„¸ìš”']
    }
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()
    
    colors = ['#FFE5B4', '#B4E5FF', '#C8FFB4', '#FFB4E5']
    
    for idx, (method, tokens) in enumerate(tokenizations.items()):
        ax = axes[idx]
        
        # í† í° ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        total_width = len(tokens) * 0.8 + (len(tokens)-1) * 0.1
        start_x = (3 - total_width) / 2
        
        for i, token in enumerate(tokens):
            x = start_x + i * 0.9
            box = FancyBboxPatch((x, 0.3), 0.8, 0.4,
                                 boxstyle="round,pad=0.05",
                                 facecolor=colors[idx], 
                                 edgecolor='black', linewidth=2)
            ax.add_patch(box)
            ax.text(x + 0.4, 0.5, token, ha='center', va='center', 
                   fontsize=14, weight='bold')
        
        ax.set_xlim(0, 3)
        ax.set_ylim(0, 1)
        ax.axis('off')
        ax.set_title(f'{method} í† í°í™”', fontsize=15, weight='bold')
        ax.text(1.5, 0.1, f'í† í° ìˆ˜: {len(tokens)}ê°œ', 
               ha='center', fontsize=12, style='italic', weight='bold')
    
    plt.suptitle('ğŸ”ª í† í°í™” ë°©ì‹ ë¹„êµ - "ì•ˆë…•í•˜ì„¸ìš”"ë¥¼ ìë¥´ëŠ” ë°©ë²•ë“¤', 
                fontsize=16, weight='bold')
    plt.tight_layout()
    plt.savefig('../output/tokenization_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def visualize_word_embedding():
    """ë‹¨ì–´ ì„ë² ë”© 2D ê³µê°„ ì‹œê°í™”"""
    # ì˜ˆì‹œ ë‹¨ì–´ë“¤ê³¼ ê°€ìƒì˜ 2D ì¢Œí‘œ
    words = {
        'ê°•ì•„ì§€': (2, 3),
        'ê³ ì–‘ì´': (2.5, 2.8),
        'ê°œ': (1.8, 3.2),
        'ì• ì™„ë™ë¬¼': (2.2, 2.5),
        'ìë™ì°¨': (-2, -1),
        'ë²„ìŠ¤': (-2.3, -0.8),
        'íƒì‹œ': (-1.8, -1.2),
        'êµí†µìˆ˜ë‹¨': (-2, -1.5),
        'ì‚¬ê³¼': (1, -2),
        'ë°”ë‚˜ë‚˜': (1.2, -2.3),
        'ê³¼ì¼': (0.8, -2.1)
    }
    
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # ì¹´í…Œê³ ë¦¬ë³„ ìƒ‰ìƒ
    categories = {
        'animal': ['ê°•ì•„ì§€', 'ê³ ì–‘ì´', 'ê°œ', 'ì• ì™„ë™ë¬¼'],
        'vehicle': ['ìë™ì°¨', 'ë²„ìŠ¤', 'íƒì‹œ', 'êµí†µìˆ˜ë‹¨'],
        'fruit': ['ì‚¬ê³¼', 'ë°”ë‚˜ë‚˜', 'ê³¼ì¼']
    }
    
    colors = {'animal': '#FFB4B4', 'vehicle': '#B4D4FF', 'fruit': '#B4FFB4'}
    
    for category, word_list in categories.items():
        for word in word_list:
            if word in words:
                x, y = words[word]
                ax.scatter(x, y, s=800, c=colors[category], edgecolor='black', 
                          linewidth=2, alpha=0.8)
                ax.annotate(word, (x, y), ha='center', va='center', 
                           fontsize=13, weight='bold')
    
    # ìœ ì‚¬ë„ ì„  ê·¸ë¦¬ê¸°
    similar_pairs = [('ê°•ì•„ì§€', 'ê°œ'), ('ìë™ì°¨', 'ë²„ìŠ¤'), ('ì‚¬ê³¼', 'ë°”ë‚˜ë‚˜')]
    for word1, word2 in similar_pairs:
        x1, y1 = words[word1]
        x2, y2 = words[word2]
        ax.plot([x1, x2], [y1, y2], 'gray', linestyle='--', alpha=0.6, linewidth=2)
    
    ax.set_xlim(-3, 3)
    ax.set_ylim(-3, 4)
    ax.grid(True, alpha=0.3)
    ax.set_xlabel('ì°¨ì› 1', fontsize=14, weight='bold')
    ax.set_ylabel('ì°¨ì› 2', fontsize=14, weight='bold')
    ax.set_title('ğŸ“ ë‹¨ì–´ ì„ë² ë”© ê³µê°„ - ë¹„ìŠ·í•œ ì˜ë¯¸ëŠ” ê°€ê¹Œì´ ëª¨ì—¬ìˆì–´ìš”!', 
                fontsize=16, weight='bold')
    
    # ë²”ë¡€
    from matplotlib.patches import Patch
    legend_elements = [Patch(facecolor=colors['animal'], label='ë™ë¬¼'),
                       Patch(facecolor=colors['vehicle'], label='êµí†µ'),
                       Patch(facecolor=colors['fruit'], label='ê³¼ì¼')]
    ax.legend(handles=legend_elements, loc='upper right', fontsize=12)
    
    plt.tight_layout()
    plt.savefig('../output/word_embedding_space.png', dpi=300, bbox_inches='tight')
    plt.show()

def analyze_real_complaint_data():
    """ì‹¤ì œ ë¯¼ì› ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”"""
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('../data/complaints_data.csv')
    
    print("=== ì‹¤ì œ ë¯¼ì› ë°ì´í„° ë¶„ì„ ê²°ê³¼ ===")
    print(f"ì´ ë¯¼ì› ìˆ˜: {len(df):,}ê±´")
    print(f"ì–¸ì–´ë³„ ë¶„í¬: í•œêµ­ì–´ {len(df[df['language']=='ko'])}ê±´, ì˜ì–´ {len(df[df['language']=='en'])}ê±´")
    
    # í•œêµ­ì–´ ë¯¼ì› ë¶„ì„
    korean_df = df[df['language'] == 'ko']
    
    # ê°ì„± ë¶„í¬ ì‹œê°í™”
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ê°ì„± ë¶„í¬
    sentiment_counts = korean_df['sentiment'].value_counts()
    colors_sentiment = ['#FF6B6B', '#FFE66D', '#4ECDC4']
    ax1.pie(sentiment_counts.values, labels=['ë¶€ì •ì ', 'ì¤‘ë¦½ì ', 'ê¸ì •ì '], 
           colors=colors_sentiment, autopct='%1.1f%%', startangle=90)
    ax1.set_title('í•œêµ­ ë¯¼ì› ê°ì„± ë¶„í¬', fontsize=14, weight='bold')
    
    # 2. ì²˜ë¦¬ ìƒíƒœ ë¶„í¬
    status_counts = korean_df['status'].value_counts()
    ax2.bar(status_counts.index, status_counts.values, 
           color=['#FF9999', '#99CCFF', '#99FF99'], edgecolor='black')
    ax2.set_title('ë¯¼ì› ì²˜ë¦¬ ìƒíƒœ ë¶„í¬', fontsize=14, weight='bold')
    ax2.set_ylabel('ë¯¼ì› ìˆ˜')
    
    # 3. ì›”ë³„ ë¯¼ì› ì ‘ìˆ˜ í˜„í™©
    korean_df['date'] = pd.to_datetime(korean_df['date'])
    korean_df['month'] = korean_df['date'].dt.to_period('M')
    monthly_counts = korean_df['month'].value_counts().sort_index()
    
    ax3.plot(range(len(monthly_counts)), monthly_counts.values, 
            marker='o', linewidth=2, markersize=6, color='#FF6B6B')
    ax3.set_title('ì›”ë³„ ë¯¼ì› ì ‘ìˆ˜ í˜„í™©', fontsize=14, weight='bold')
    ax3.set_ylabel('ë¯¼ì› ìˆ˜')
    ax3.set_xlabel('ì›”')
    ax3.grid(True, alpha=0.3)
    
    # 4. ì§€ì—­ë³„ ë¯¼ì› í˜„í™© (ìƒìœ„ 10ê°œ)
    location_counts = korean_df['location'].value_counts().head(10)
    ax4.barh(range(len(location_counts)), location_counts.values, color='#4ECDC4')
    ax4.set_yticks(range(len(location_counts)))
    ax4.set_yticklabels(location_counts.index, fontsize=10)
    ax4.set_title('ì§€ì—­ë³„ ë¯¼ì› í˜„í™© (ìƒìœ„ 10ê°œ)', fontsize=14, weight='bold')
    ax4.set_xlabel('ë¯¼ì› ìˆ˜')
    
    plt.tight_layout()
    plt.savefig('../output/complaint_analysis_overview.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return korean_df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì œ4ì¥ 4.1ì ˆ: NLP íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ì‹¤ìŠµ ì‹œì‘!")
    print("=" * 60)
    
    # 1. NLP íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
    print("1ï¸âƒ£ NLP ì²˜ë¦¬ ê³¼ì • ì‹œê°í™”...")
    draw_nlp_pipeline()
    
    # 2. ë¯¼ì› ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì‹œê°í™”
    print("2ï¸âƒ£ ë¯¼ì› ì¹´í…Œê³ ë¦¬ ë¶„í¬ ë¶„ì„...")
    categories = visualize_complaint_categories()
    
    # 3. í•œêµ­ì–´ vs ì˜ì–´ ì²˜ë¦¬ ë¹„êµ
    print("3ï¸âƒ£ í•œêµ­ì–´ì™€ ì˜ì–´ ì²˜ë¦¬ ì°¨ì´ ì‹œê°í™”...")
    compare_korean_english()
    
    # 4. í† í°í™” ë°©ì‹ ë¹„êµ
    print("4ï¸âƒ£ í† í°í™” ë°©ì‹ ë¹„êµ ì‹œê°í™”...")
    visualize_tokenization()
    
    # 5. ë‹¨ì–´ ì„ë² ë”© ê³µê°„ ì‹œê°í™”
    print("5ï¸âƒ£ ë‹¨ì–´ ì„ë² ë”© ê³µê°„ ì‹œê°í™”...")
    visualize_word_embedding()
    
    # 6. ì‹¤ì œ ë¯¼ì› ë°ì´í„° ë¶„ì„
    print("6ï¸âƒ£ ì‹¤ì œ ë¯¼ì› ë°ì´í„° ë¶„ì„...")
    korean_df = analyze_real_complaint_data()
    
    print("\nâœ… 4.1ì ˆ ì‹¤ìŠµ ì™„ë£Œ!")
    print("ğŸ“ ê²°ê³¼ ì´ë¯¸ì§€ë“¤ì´ ../output/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ë¶„ì„ ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
    print(f"â€¢ ê°€ì¥ ë§ì€ ë¯¼ì› ì¹´í…Œê³ ë¦¬: {categories.index[0]} ({categories.iloc[0]}ê±´)")
    print(f"â€¢ ì „ì²´ í•œêµ­ì–´ ë¯¼ì› ì¤‘ ë¶€ì •ì  ê°ì„±: {len(korean_df[korean_df['sentiment']=='negative'])/len(korean_df)*100:.1f}%")
    print(f"â€¢ ì²˜ë¦¬ ì™„ë£Œëœ ë¯¼ì› ë¹„ìœ¨: {len(korean_df[korean_df['status']=='ì™„ë£Œ'])/len(korean_df)*100:.1f}%")

if __name__ == "__main__":
    main()
