"""
ì œ4ì¥ 4.3ì ˆ: ë¯¼ì› ë¶„ë¥˜ AI ë§Œë“¤ê¸° ì‹¤ìŠµ
ì‹¤ì œ ë¯¼ì› ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•˜ê³  í‰ê°€
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import re
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

def load_and_explore_data():
    """ë¯¼ì› ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë¶„ì„"""
    print("ğŸ“ ë¯¼ì› ë°ì´í„° ë¡œë”© ì¤‘...")
    df = pd.read_csv('../data/complaints_data.csv')
    
    # í•œêµ­ì–´ ë¯¼ì›ë§Œ í•„í„°ë§
    korean_df = df[df['language'] == 'ko'].copy()
    
    print(f"âœ… ì´ {len(korean_df)}ê±´ì˜ í•œêµ­ì–´ ë¯¼ì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„í¬:")
    print(korean_df['category'].value_counts())
    
    return korean_df

def clean_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    if pd.isna(text):
        return ""
    
    # 1. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text = text.strip()
    
    # 2. ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = ' '.join(text.split())
    
    # 3. íŠ¹ìˆ˜ë¬¸ì ì¼ë¶€ ì œê±° (ì„ íƒì‚¬í•­)
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    
    # 4. ë‹¤ì‹œ ê³µë°± ì •ë¦¬
    text = ' '.join(text.split())
    
    return text

def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬"""
    print("ğŸ§¹ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬
    df['cleaned_text'] = df['text'].apply(clean_text)
    
    # ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°
    df = df[df['cleaned_text'].str.len() > 0].copy()
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„
    df['text_length'] = df['cleaned_text'].str.len()
    
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ. ìµœì¢… ë°ì´í„°: {len(df)}ê±´")
    print(f"ğŸ“ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {df['text_length'].mean():.1f}ì")
    
    return df

def classify_complaint_simple(text):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨ ë¶„ë¥˜ê¸°"""
    
    # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ
    keywords = {
        'êµí†µ': ['ë„ë¡œ', 'ì‹ í˜¸ë“±', 'ì£¼ì°¨', 'êµí†µ', 'ì°¨ëŸ‰', 'í¬íŠ¸í™€', 'ë²„ìŠ¤', 'ì§€í•˜ì² '],
        'í™˜ê²½': ['ì“°ë ˆê¸°', 'ì†ŒìŒ', 'ì˜¤ì—¼', 'ì²­ì†Œ', 'ì¬í™œìš©', 'ë¯¸ì„¸ë¨¼ì§€', 'ê³µì›', 'ë…¹ì§€'],
        'ì•ˆì „': ['ê°€ë¡œë“±', 'ì¹˜ì•ˆ', 'CCTV', 'ìœ„í—˜', 'ì‚¬ê³ ', 'ë²”ì£„', 'ì•ˆì „ì‹œì„¤'],
        'ë³µì§€': ['ë†€ì´í„°', 'ë³µì§€ê´€', 'ì–´ë¦°ì´ì§‘', 'ê²½ë¡œë‹¹', 'ì‹œì„¤', 'ê¸°ì´ˆì—°ê¸ˆ', 'ì§€ì›ê¸ˆ'],
        'í–‰ì •': ['ë¯¼ì›ì²˜ë¦¬', 'ê³µë¬´ì›', 'ì„œë¥˜ë°œê¸‰', 'ì˜¨ë¼ì¸', 'í–‰ì •ì ˆì°¨', 'ì‹œìŠ¤í…œ']
    }
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
    scores = {}
    for category, words in keywords.items():
        score = sum(1 for word in words if word in text)
        scores[category] = score
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
    if max(scores.values()) > 0:
        return max(scores, key=scores.get)
    else:
        return 'ê¸°íƒ€'

def simple_keyword_classifier(df):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì‹¤í–‰ ë° í‰ê°€"""
    print("ğŸ·ï¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì‹¤í–‰ ì¤‘...")
    
    # ë¶„ë¥˜ ì‹¤í–‰
    df['predicted_simple'] = df['cleaned_text'].apply(classify_complaint_simple)
    
    # ì •í™•ë„ ê³„ì‚°
    accuracy = accuracy_score(df['category'], df['predicted_simple'])
    
    print(f"âœ… í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì •í™•ë„: {accuracy:.3f} ({accuracy*100:.1f}%)")
    
    return df, accuracy

def tfidf_classifier(df):
    """TF-IDF + ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ê¸°"""
    print("ğŸ¤– TF-IDF ê¸°ë°˜ ë¶„ë¥˜ê¸° í•™ìŠµ ì¤‘...")
    
    # ë°ì´í„° ë¶„í• 
    X = df['cleaned_text']
    y = df['category']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # TF-IDF ë²¡í„°í™”
    vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)
    
    # ì—¬ëŸ¬ ë¶„ë¥˜ê¸° í•™ìŠµ
    classifiers = {
        'Naive Bayes': MultinomialNB(),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)
    }
    
    results = {}
    
    for name, clf in classifiers.items():
        # ëª¨ë¸ í•™ìŠµ
        clf.fit(X_train_tfidf, y_train)
        
        # ì˜ˆì¸¡
        y_pred = clf.predict(X_test_tfidf)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = accuracy_score(y_test, y_pred)
        results[name] = {
            'accuracy': accuracy,
            'y_test': y_test,
            'y_pred': y_pred
        }
        
        print(f"âœ… {name} ì •í™•ë„: {accuracy:.3f} ({accuracy*100:.1f}%)")
    
    return results, vectorizer

def visualize_classification_results(simple_accuracy, ml_results):
    """ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    
    # ëª¨ë“  ê²°ê³¼ ì •ë¦¬
    all_results = {'í‚¤ì›Œë“œ ê¸°ë°˜': simple_accuracy}
    for name, result in ml_results.items():
        all_results[name] = result['accuracy']
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # 1. ëª¨ë¸ë³„ ì •í™•ë„ ë¹„êµ
    models = list(all_results.keys())
    accuracies = [acc * 100 for acc in all_results.values()]
    colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFCC99']
    
    bars = ax1.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5)
    ax1.set_ylabel('ì •í™•ë„ (%)', fontsize=13, weight='bold')
    ax1.set_title('ë¶„ë¥˜ ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ', fontsize=14, weight='bold')
    ax1.set_ylim(0, 100)
    ax1.grid(axis='y', alpha=0.3)
    
    # ê°’ í‘œì‹œ
    for bar, acc in zip(bars, accuracies):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                f'{acc:.1f}%', ha='center', va='bottom', fontsize=11, weight='bold')
    
    # 2. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ í˜¼ë™ í–‰ë ¬
    best_model_name = max(ml_results.keys(), key=lambda x: ml_results[x]['accuracy'])
    best_result = ml_results[best_model_name]
    
    cm = confusion_matrix(best_result['y_test'], best_result['y_pred'])
    categories = sorted(best_result['y_test'].unique())
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=categories, yticklabels=categories, ax=ax2)
    ax2.set_title(f'{best_model_name} í˜¼ë™ í–‰ë ¬', fontsize=14, weight='bold')
    ax2.set_xlabel('ì˜ˆì¸¡ ì¹´í…Œê³ ë¦¬', fontsize=12)
    ax2.set_ylabel('ì‹¤ì œ ì¹´í…Œê³ ë¦¬', fontsize=12)
    
    plt.tight_layout()
    plt.savefig('../output/classification_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return best_model_name

def analyze_misclassifications(df, ml_results):
    """ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„"""
    print("ğŸ” ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„ ì¤‘...")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
    best_model_name = max(ml_results.keys(), key=lambda x: ml_results[x]['accuracy'])
    best_result = ml_results[best_model_name]
    
    # ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ì°¾ê¸°
    test_indices = df.index[-len(best_result['y_test']):]  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¸ë±ìŠ¤
    misclassified = []
    
    for i, (true_label, pred_label) in enumerate(zip(best_result['y_test'], best_result['y_pred'])):
        if true_label != pred_label:
            original_idx = test_indices[i]
            misclassified.append({
                'text': df.loc[original_idx, 'cleaned_text'],
                'true_category': true_label,
                'predicted_category': pred_label
            })
    
    print(f"ğŸ“Š ì´ {len(misclassified)}ê±´ì˜ ì˜¤ë¶„ë¥˜ ë°œê²¬")
    
    # ì˜¤ë¶„ë¥˜ íŒ¨í„´ ë¶„ì„
    error_patterns = Counter()
    for error in misclassified:
        pattern = f"{error['true_category']} â†’ {error['predicted_category']}"
        error_patterns[pattern] += 1
    
    print("ğŸ”„ ì£¼ìš” ì˜¤ë¶„ë¥˜ íŒ¨í„´:")
    for pattern, count in error_patterns.most_common(5):
        print(f"   {pattern}: {count}ê±´")
    
    # ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ìƒ˜í”Œ ì¶œë ¥
    print("\nğŸ“ ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ìƒ˜í”Œ:")
    for i, error in enumerate(misclassified[:3]):
        print(f"\n{i+1}. í…ìŠ¤íŠ¸: {error['text'][:50]}...")
        print(f"   ì‹¤ì œ: {error['true_category']} | ì˜ˆì¸¡: {error['predicted_category']}")
    
    return misclassified

def find_topics_simple(texts, n_topics=5):
    """ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ ê°„ë‹¨ í† í”½ ì°¾ê¸°"""
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    all_text = ' '.join(texts)
    
    # ë‹¨ì–´ ë¶„ë¦¬
    words = all_text.split()
    
    # ë¶ˆìš©ì–´ ì œê±° (ê°„ë‹¨ ë²„ì „)
    stopwords = ['ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ëŠ”', 'ì€', 'ì˜', 'ë„', 'ë§Œ', 'ë¶€í„°', 'ê¹Œì§€', 'í•˜ê³ ', 'ê·¸ë¦¬ê³ ']
    words = [w for w in words if w not in stopwords and len(w) > 1]
    
    # ìƒìœ„ ë¹ˆì¶œ ë‹¨ì–´ ì°¾ê¸°
    word_counts = Counter(words)
    top_words = word_counts.most_common(n_topics)
    
    return top_words

def visualize_topics_and_trends(df):
    """í† í”½ ë¶„ì„ ë° íŠ¸ë Œë“œ ì‹œê°í™”"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
    topics = find_topics_simple(df['cleaned_text'].tolist())
    words = [w for w, c in topics]
    counts = [c for w, c in topics]
    
    colors = plt.cm.Set3(range(len(words)))
    ax1.bar(words, counts, color=colors, edgecolor='black', linewidth=1.5)
    ax1.set_title('ë¯¼ì› ì£¼ìš” í‚¤ì›Œë“œ (í† í”½)', fontsize=14, weight='bold')
    ax1.set_xlabel('í‚¤ì›Œë“œ', fontsize=12)
    ax1.set_ylabel('ë“±ì¥ íšŸìˆ˜', fontsize=12)
    ax1.tick_params(axis='x', rotation=45)
    
    # 2. ì¹´í…Œê³ ë¦¬ë³„ ê°ì„± ë¶„í¬
    sentiment_by_category = pd.crosstab(df['category'], df['sentiment'])
    sentiment_by_category.plot(kind='bar', ax=ax2, color=['#FF6B6B', '#FFE66D', '#4ECDC4'])
    ax2.set_title('ì¹´í…Œê³ ë¦¬ë³„ ê°ì„± ë¶„í¬', fontsize=14, weight='bold')
    ax2.set_xlabel('ì¹´í…Œê³ ë¦¬', fontsize=12)
    ax2.set_ylabel('ë¯¼ì› ìˆ˜', fontsize=12)
    ax2.legend(['ë¶€ì •ì ', 'ì¤‘ë¦½ì ', 'ê¸ì •ì '])
    ax2.tick_params(axis='x', rotation=45)
    
    # 3. í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬
    ax3.hist(df['text_length'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
    ax3.axvline(df['text_length'].mean(), color='red', linestyle='--', linewidth=2, label=f'í‰ê· : {df["text_length"].mean():.0f}ì')
    ax3.set_title('ë¯¼ì› í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬', fontsize=14, weight='bold')
    ax3.set_xlabel('í…ìŠ¤íŠ¸ ê¸¸ì´ (ê¸€ì ìˆ˜)', fontsize=12)
    ax3.set_ylabel('ë¹ˆë„', fontsize=12)
    ax3.legend()
    
    # 4. ì²˜ë¦¬ ìƒíƒœë³„ ë¶„í¬
    status_counts = df['status'].value_counts()
    colors_status = ['#FF9999', '#99CCFF', '#99FF99']
    ax4.pie(status_counts.values, labels=status_counts.index, colors=colors_status, 
           autopct='%1.1f%%', startangle=90)
    ax4.set_title('ë¯¼ì› ì²˜ë¦¬ ìƒíƒœ ë¶„í¬', fontsize=14, weight='bold')
    
    plt.tight_layout()
    plt.savefig('../output/topics_and_trends.png', dpi=300, bbox_inches='tight')
    plt.show()

def generate_insights_report(df, simple_accuracy, ml_results, misclassified):
    """ë¶„ì„ ê²°ê³¼ ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    best_model_name = max(ml_results.keys(), key=lambda x: ml_results[x]['accuracy'])
    best_accuracy = ml_results[best_model_name]['accuracy']
    
    report = f"""
=== ë¯¼ì› ë¶„ë¥˜ AI ë¶„ì„ ë¦¬í¬íŠ¸ ===

ğŸ“Š ë°ì´í„° ê°œìš”:
â€¢ ì´ ë¯¼ì› ìˆ˜: {len(df):,}ê±´
â€¢ ì¹´í…Œê³ ë¦¬ ìˆ˜: {df['category'].nunique()}ê°œ
â€¢ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {df['text_length'].mean():.1f}ì

ğŸ¯ ëª¨ë¸ ì„±ëŠ¥:
â€¢ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸°: {simple_accuracy*100:.1f}%
â€¢ ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name} ({best_accuracy*100:.1f}%)
â€¢ ì„±ëŠ¥ í–¥ìƒ: +{(best_accuracy - simple_accuracy)*100:.1f}%p

ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­:
â€¢ ê°€ì¥ ë§ì€ ë¯¼ì› ì¹´í…Œê³ ë¦¬: {df['category'].value_counts().index[0]} ({df['category'].value_counts().iloc[0]}ê±´)
â€¢ ë¶€ì •ì  ê°ì„± ë¹„ìœ¨: {len(df[df['sentiment']=='negative'])/len(df)*100:.1f}%
â€¢ ì˜¤ë¶„ë¥˜ ê±´ìˆ˜: {len(misclassified)}ê±´ ({len(misclassified)/len(df)*100:.1f}%)

ğŸ’¡ ê°œì„  ì œì•ˆ:
1. ë” ë§ì€ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ (í˜„ì¬ {len(df)}ê±´ â†’ ëª©í‘œ 5,000ê±´+)
2. í•œêµ­ì–´ íŠ¹í™” ì „ì²˜ë¦¬ ê°•í™” (í˜•íƒœì†Œ ë¶„ì„ ë„ì…)
3. KoBERT ë“± ì‚¬ì „í•™ìŠµ ëª¨ë¸ í™œìš©
4. ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ

ğŸš€ ì‹¤ë¬´ ì ìš© ë°©ì•ˆ:
â€¢ ì‹¤ì‹œê°„ ë¯¼ì› ìë™ ë¶„ë¥˜ ì‹œìŠ¤í…œ êµ¬ì¶•
â€¢ ë¯¼ì› ì²˜ë¦¬ ìš°ì„ ìˆœìœ„ ìë™ ê²°ì •
â€¢ ë°˜ë³µ ë¯¼ì› íŒ¨í„´ ìë™ ê°ì§€
â€¢ ì •ì±… ì´ìŠˆ íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§
"""
    
    print(report)
    
    # ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    with open('../output/classification_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    return report

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ’» ì œ4ì¥ 4.3ì ˆ: ë¯¼ì› ë¶„ë¥˜ AI ë§Œë“¤ê¸° ì‹¤ìŠµ ì‹œì‘!")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
    print("1ï¸âƒ£ ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰...")
    df = load_and_explore_data()
    
    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    print("\n2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬...")
    df = preprocess_data(df)
    
    # 3. í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸°
    print("\n3ï¸âƒ£ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì‹¤í–‰...")
    df, simple_accuracy = simple_keyword_classifier(df)
    
    # 4. TF-IDF ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ê¸°
    print("\n4ï¸âƒ£ TF-IDF ê¸°ë°˜ ë¶„ë¥˜ê¸° í•™ìŠµ...")
    ml_results, vectorizer = tfidf_classifier(df)
    
    # 5. ê²°ê³¼ ì‹œê°í™”
    print("\n5ï¸âƒ£ ë¶„ë¥˜ ê²°ê³¼ ì‹œê°í™”...")
    best_model_name = visualize_classification_results(simple_accuracy, ml_results)
    
    # 6. ì˜¤ë¶„ë¥˜ ë¶„ì„
    print("\n6ï¸âƒ£ ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„...")
    misclassified = analyze_misclassifications(df, ml_results)
    
    # 7. í† í”½ ë° íŠ¸ë Œë“œ ë¶„ì„
    print("\n7ï¸âƒ£ í† í”½ ë° íŠ¸ë Œë“œ ë¶„ì„...")
    visualize_topics_and_trends(df)
    
    # 8. ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
    print("\n8ï¸âƒ£ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±...")
    report = generate_insights_report(df, simple_accuracy, ml_results, misclassified)
    
    print("\nâœ… 4.3ì ˆ ì‹¤ìŠµ ì™„ë£Œ!")
    print("ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì´ ../output/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name} ({ml_results[best_model_name]['accuracy']*100:.1f}%)")

if __name__ == "__main__":
    main()
